{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06fea3d",
   "metadata": {},
   "source": [
    "# 学習と評価\n",
    " - FaceNetの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8fdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51b929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d712f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c978fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d763348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8b5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83471da0",
   "metadata": {},
   "source": [
    "## データのロード\n",
    "\n",
    "- 画像サイズは224×224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c4d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36eab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Caring</th>\n",
       "      <th>Confident</th>\n",
       "      <th>Emotionally stable</th>\n",
       "      <th>Intelligent</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Sociable</th>\n",
       "      <th>Trustworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>330524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>35629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>312270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>127529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>394899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>13583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Caring  Confident  Emotionally stable  Intelligent  Responsible  \\\n",
       "0    368079     0.0        0.0                 0.0          0.0          0.0   \n",
       "1    438384     1.0        1.0                 0.0          1.0          0.0   \n",
       "2     30155     1.0        1.0                 1.0          0.0          1.0   \n",
       "3    270812     0.0        0.0                 1.0          0.0          0.0   \n",
       "4    330524     0.0        1.0                 0.0          0.0          0.0   \n",
       "..      ...     ...        ...                 ...          ...          ...   \n",
       "250   35629     1.0        1.0                 0.0          0.0          0.0   \n",
       "251  312270     0.0        1.0                 0.0          0.0          0.0   \n",
       "252  127529     1.0        1.0                 1.0          0.0          0.0   \n",
       "253  394899     0.0        1.0                 0.0          0.0          0.0   \n",
       "254   13583     0.0        0.0                 0.0          0.0          1.0   \n",
       "\n",
       "     Sociable  Trustworthy  \n",
       "0         1.0          0.0  \n",
       "1         1.0          0.0  \n",
       "2         1.0          1.0  \n",
       "3         0.0          0.0  \n",
       "4         0.0          0.0  \n",
       "..        ...          ...  \n",
       "250       0.0          0.0  \n",
       "251       0.0          0.0  \n",
       "252       0.0          0.0  \n",
       "253       0.0          0.0  \n",
       "254       0.0          0.0  \n",
       "\n",
       "[255 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ecd64",
   "metadata": {},
   "source": [
    "## FaceNetで埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698ddb",
   "metadata": {},
   "source": [
    "メモ：```\\Lib\\site-packages\\facenet\\src\\facenet.py```の408行目をtensorflow v2仕様に書き換える必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bbf47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_embedding import FaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8b7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: ../facenet//20180402-114759/20180402-114759.pb\n",
      "WARNING:tensorflow:From C:\\Users\\Owner\\python_venvs\\tensorflow\\lib\\site-packages\\facenet\\src\\facenet.py:407: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "FACE_MEDEL_PATH = '../facenet//20180402-114759/20180402-114759.pb'\n",
    "face_embedding = FaceEmbedding(FACE_MEDEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6301e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_id in df[\"Id\"]:\n",
    "    path = f\"images/cleaned_20220519/{img_id}.jpg\"\n",
    "    face_vec = face_embedding.face_embeddings(path)[0]\n",
    "    X.append(face_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e77dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147fc0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546d6f1",
   "metadata": {},
   "source": [
    "# 二値分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4ca29",
   "metadata": {},
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d63c3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPool2D, Lambda, Conv2D, Reshape, Input, RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "016fb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_model():\n",
    "    input_ts = Input(shape=(512,))\n",
    "    dense1 = Dense(512, activation=\"relu\")(input_ts)\n",
    "    dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "    drop1 = Dropout(0.4, seed=SEED)(dense2)\n",
    "    dense3 = Dense(1024, activation=\"relu\")(drop1)\n",
    "    drop2 = Dropout(0.4, seed=SEED)(dense3)\n",
    "    dense4 = Dense(512, activation=\"relu\")(drop2)\n",
    "    dense5 = Dense(256, activation=\"relu\")(dense4)\n",
    "    dense6 = Dense(128, activation=\"relu\")(dense5)\n",
    "    drop3 = Dropout(0.2, seed=SEED)(dense6)\n",
    "    final = Dense(2, activation=\"softmax\")(drop3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_ts],\n",
    "        outputs=[final]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d25ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158b5902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,526,850\n",
      "Trainable params: 2,526,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565e1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c957700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bb8a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19ff1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4d914",
   "metadata": {},
   "source": [
    "cf. https://www.kaggle.com/code/rejpalcz/best-loss-function-for-f1-score-metric/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c9f2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8efe50",
   "metadata": {},
   "source": [
    "## すべてのラベルでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "449383e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Caring\",\"Confident\",\"Emotionally stable\",\"Intelligent\",\"Responsible\",\"Sociable\",\"Trustworthy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e9da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64b3039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0df294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b530f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caring\n",
      "origin pos:18.0 neg:95.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 51ms/step - loss: 0.7389 - tp: 92.0000 - fp: 29.0000 - tn: 92.0000 - fn: 29.0000 - accuracy: 0.7603 - precision: 0.7603 - recall: 0.7603 - auc: 0.8115 - val_loss: 0.6368 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8359\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6846 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.8973 - val_loss: 0.5988 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8312\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5853 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9480 - val_loss: 0.6123 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.8203\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4419 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9513 - val_loss: 2.3647 - val_tp: 14.0000 - val_fp: 43.0000 - val_tn: 14.0000 - val_fn: 43.0000 - val_accuracy: 0.2456 - val_precision: 0.2456 - val_recall: 0.2456 - val_auc: 0.2478\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4329 - tp: 96.0000 - fp: 17.0000 - tn: 96.0000 - fn: 17.0000 - accuracy: 0.8496 - precision: 0.8496 - recall: 0.8496 - auc: 0.8812 - val_loss: 1.1639 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.8030\n",
      "Predict: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0]\n",
      "F1 score: 0.15384615384615383\n",
      "origin pos:19.0 neg:94.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.6896 - tp: 123.0000 - fp: 47.0000 - tn: 123.0000 - fn: 47.0000 - accuracy: 0.7235 - precision: 0.7235 - recall: 0.7235 - auc: 0.7636 - val_loss: 0.5960 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.7799\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6938 - tp: 92.0000 - fp: 21.0000 - tn: 92.0000 - fn: 21.0000 - accuracy: 0.8142 - precision: 0.8142 - recall: 0.8142 - auc: 0.8642 - val_loss: 0.6383 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.7722\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5347 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9168 - val_loss: 1.1154 - val_tp: 21.0000 - val_fp: 36.0000 - val_tn: 21.0000 - val_fn: 36.0000 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_auc: 0.3866\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3286 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9319 - val_loss: 1.2091 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.7713\n",
      "Predict: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 1 1 1]\n",
      "True: [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0]\n",
      "F1 score: 0.07142857142857142\n",
      "origin pos:18.0 neg:95.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 42ms/step - loss: 0.7130 - tp: 129.0000 - fp: 41.0000 - tn: 129.0000 - fn: 41.0000 - accuracy: 0.7588 - precision: 0.7588 - recall: 0.7588 - auc: 0.7557 - val_loss: 0.6563 - val_tp: 54.0000 - val_fp: 3.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.9474 - val_precision: 0.9474 - val_recall: 0.9474 - val_auc: 0.9800\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6752 - tp: 83.0000 - fp: 30.0000 - tn: 83.0000 - fn: 30.0000 - accuracy: 0.7345 - precision: 0.7345 - recall: 0.7345 - auc: 0.8422 - val_loss: 0.4443 - val_tp: 54.0000 - val_fp: 3.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.9474 - val_precision: 0.9474 - val_recall: 0.9474 - val_auc: 0.9794\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5380 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.9457 - val_loss: 0.5902 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.6922\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4367 - tp: 97.0000 - fp: 16.0000 - tn: 97.0000 - fn: 16.0000 - accuracy: 0.8584 - precision: 0.8584 - recall: 0.8584 - auc: 0.9490 - val_loss: 0.3491 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.9548\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2453 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9352 - val_loss: 0.1770 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9581\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2716 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9540 - val_loss: 0.6053 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7966\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1143 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9766 - val_loss: 0.3013 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.9474\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2258 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9711 - val_loss: 0.2953 - val_tp: 52.0000 - val_fp: 5.0000 - val_tn: 52.0000 - val_fn: 5.0000 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_auc: 0.9609\n",
      "Predict: [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 1 1]\n",
      "F1 score: 0.17647058823529413\n",
      "Confident\n",
      "origin pos:52.0 neg:61.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.7045 - tp: 103.0000 - fp: 67.0000 - tn: 103.0000 - fn: 67.0000 - accuracy: 0.6059 - precision: 0.6059 - recall: 0.6059 - auc: 0.7165 - val_loss: 0.6919 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5420\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6928 - tp: 60.0000 - fp: 53.0000 - tn: 60.0000 - fn: 53.0000 - accuracy: 0.5310 - precision: 0.5310 - recall: 0.5310 - auc: 0.5667 - val_loss: 0.6917 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5291\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6865 - tp: 61.0000 - fp: 52.0000 - tn: 61.0000 - fn: 52.0000 - accuracy: 0.5398 - precision: 0.5398 - recall: 0.5398 - auc: 0.5980 - val_loss: 0.6903 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.5432\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6391 - tp: 77.0000 - fp: 36.0000 - tn: 77.0000 - fn: 36.0000 - accuracy: 0.6814 - precision: 0.6814 - recall: 0.6814 - auc: 0.7364 - val_loss: 0.7023 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5208\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6112 - tp: 76.0000 - fp: 37.0000 - tn: 76.0000 - fn: 37.0000 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - auc: 0.7059 - val_loss: 0.7418 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5768\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3727 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9072 - val_loss: 1.3073 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.5423\n",
      "Predict: [0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 0 1 0]\n",
      "True: [0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 1 1 1 0]\n",
      "F1 score: 0.4878048780487805\n",
      "origin pos:59.0 neg:54.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.7024 - tp: 85.0000 - fp: 85.0000 - tn: 85.0000 - fn: 85.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.5075 - val_loss: 0.6910 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5436\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.7035 - tp: 56.0000 - fp: 57.0000 - tn: 56.0000 - fn: 57.0000 - accuracy: 0.4956 - precision: 0.4956 - recall: 0.4956 - auc: 0.4726 - val_loss: 0.6930 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5075\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6821 - tp: 62.0000 - fp: 51.0000 - tn: 62.0000 - fn: 51.0000 - accuracy: 0.5487 - precision: 0.5487 - recall: 0.5487 - auc: 0.6219 - val_loss: 0.6943 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5057\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6229 - tp: 72.0000 - fp: 41.0000 - tn: 72.0000 - fn: 41.0000 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - auc: 0.6946 - val_loss: 0.7062 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.5454\n",
      "Predict: [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1]\n",
      "True: [1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 1 1 0]\n",
      "F1 score: 0.27586206896551724\n",
      "origin pos:57.0 neg:56.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.7014 - tp: 88.0000 - fp: 82.0000 - tn: 88.0000 - fn: 82.0000 - accuracy: 0.5176 - precision: 0.5176 - recall: 0.5176 - auc: 0.5162 - val_loss: 0.6941 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.4854\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6899 - tp: 51.0000 - fp: 62.0000 - tn: 51.0000 - fn: 62.0000 - accuracy: 0.4513 - precision: 0.4513 - recall: 0.4513 - auc: 0.5151 - val_loss: 0.6973 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5055\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6560 - tp: 65.0000 - fp: 48.0000 - tn: 65.0000 - fn: 48.0000 - accuracy: 0.5752 - precision: 0.5752 - recall: 0.5752 - auc: 0.6852 - val_loss: 0.7464 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4004\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5106 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.8271 - val_loss: 1.2423 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4211\n",
      "Predict: [1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True: [0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1\n",
      " 0 1 0 1 0 0 0 1 1 1 1]\n",
      "F1 score: 0.6078431372549019\n",
      "Emotionally stable\n",
      "origin pos:32.0 neg:81.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7415 - tp: 105.0000 - fp: 65.0000 - tn: 105.0000 - fn: 65.0000 - accuracy: 0.6176 - precision: 0.6176 - recall: 0.6176 - auc: 0.5546 - val_loss: 0.6848 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8224\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6941 - tp: 59.0000 - fp: 54.0000 - tn: 59.0000 - fn: 54.0000 - accuracy: 0.5221 - precision: 0.5221 - recall: 0.5221 - auc: 0.5305 - val_loss: 0.6878 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8095\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6832 - tp: 81.0000 - fp: 32.0000 - tn: 81.0000 - fn: 32.0000 - accuracy: 0.7168 - precision: 0.7168 - recall: 0.7168 - auc: 0.7851 - val_loss: 0.6189 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8215\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6056 - tp: 81.0000 - fp: 32.0000 - tn: 81.0000 - fn: 32.0000 - accuracy: 0.7168 - precision: 0.7168 - recall: 0.7168 - auc: 0.8626 - val_loss: 0.5524 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.8086\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4760 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9399 - val_loss: 0.8283 - val_tp: 38.0000 - val_fp: 19.0000 - val_tn: 38.0000 - val_fn: 19.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7547\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2738 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9644 - val_loss: 1.4519 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.7593\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3486 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9319 - val_loss: 1.6020 - val_tp: 35.0000 - val_fp: 22.0000 - val_tn: 35.0000 - val_fn: 22.0000 - val_accuracy: 0.6140 - val_precision: 0.6140 - val_recall: 0.6140 - val_auc: 0.5586\n",
      "Predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1\n",
      " 0 0 0 1 1 0 0 1 1 0 1]\n",
      "True: [0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0]\n",
      "F1 score: 0.10256410256410256\n",
      "origin pos:27.0 neg:86.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.7083 - tp: 67.0000 - fp: 103.0000 - tn: 67.0000 - fn: 103.0000 - accuracy: 0.3941 - precision: 0.3941 - recall: 0.3941 - auc: 0.4392 - val_loss: 0.6372 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8529\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7189 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.7333 - val_loss: 0.6764 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8076\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6686 - tp: 87.0000 - fp: 26.0000 - tn: 87.0000 - fn: 26.0000 - accuracy: 0.7699 - precision: 0.7699 - recall: 0.7699 - auc: 0.8467 - val_loss: 0.5148 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8215\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6526 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8677 - val_loss: 0.6206 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.6970\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4663 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9428 - val_loss: 1.0030 - val_tp: 37.0000 - val_fp: 20.0000 - val_tn: 37.0000 - val_fn: 20.0000 - val_accuracy: 0.6491 - val_precision: 0.6491 - val_recall: 0.6491 - val_auc: 0.7196\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2715 - tp: 102.0000 - fp: 11.0000 - tn: 102.0000 - fn: 11.0000 - accuracy: 0.9027 - precision: 0.9027 - recall: 0.9027 - auc: 0.9519 - val_loss: 1.4072 - val_tp: 36.0000 - val_fp: 21.0000 - val_tn: 36.0000 - val_fn: 21.0000 - val_accuracy: 0.6316 - val_precision: 0.6316 - val_recall: 0.6316 - val_auc: 0.6716\n",
      "Predict: [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1]\n",
      "True: [0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0]\n",
      "F1 score: 0.24390243902439024\n",
      "origin pos:22.0 neg:91.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7134 - tp: 119.0000 - fp: 51.0000 - tn: 119.0000 - fn: 51.0000 - accuracy: 0.7000 - precision: 0.7000 - recall: 0.7000 - auc: 0.6883 - val_loss: 0.6708 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8292\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6816 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8615 - val_loss: 0.5688 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8049\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6247 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.9093 - val_loss: 0.6134 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.7759\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4198 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9801 - val_loss: 1.5563 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.7812\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3527 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9584 - val_loss: 2.4171 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5559\n",
      "Predict: [1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0\n",
      " 0 0 0 0 1 1 1 0 1 0 0]\n",
      "True: [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1]\n",
      "F1 score: 0.5151515151515151\n",
      "Intelligent\n",
      "origin pos:32.0 neg:81.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 45ms/step - loss: 0.6995 - tp: 93.0000 - fp: 77.0000 - tn: 93.0000 - fn: 77.0000 - accuracy: 0.5471 - precision: 0.5471 - recall: 0.5471 - auc: 0.5644 - val_loss: 0.6655 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.6273\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6893 - tp: 82.0000 - fp: 31.0000 - tn: 82.0000 - fn: 31.0000 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - auc: 0.7537 - val_loss: 0.7252 - val_tp: 16.0000 - val_fp: 41.0000 - val_tn: 16.0000 - val_fn: 41.0000 - val_accuracy: 0.2807 - val_precision: 0.2807 - val_recall: 0.2807 - val_auc: 0.1967\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6673 - tp: 60.0000 - fp: 53.0000 - tn: 60.0000 - fn: 53.0000 - accuracy: 0.5310 - precision: 0.5310 - recall: 0.5310 - auc: 0.5619 - val_loss: 0.7168 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6405\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6128 - tp: 82.0000 - fp: 31.0000 - tn: 82.0000 - fn: 31.0000 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - auc: 0.7794 - val_loss: 0.8715 - val_tp: 24.0000 - val_fp: 33.0000 - val_tn: 24.0000 - val_fn: 33.0000 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_auc: 0.3730\n",
      "Predict: [1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1\n",
      " 1 0 0 1 1 0 1 1 1 1 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0]\n",
      "F1 score: 0.27692307692307694\n",
      "origin pos:31.0 neg:82.0\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 42ms/step - loss: 0.7172 - tp: 100.0000 - fp: 70.0000 - tn: 100.0000 - fn: 70.0000 - accuracy: 0.5882 - precision: 0.5882 - recall: 0.5882 - auc: 0.5469 - val_loss: 0.6832 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7415\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6941 - tp: 47.0000 - fp: 66.0000 - tn: 47.0000 - fn: 66.0000 - accuracy: 0.4159 - precision: 0.4159 - recall: 0.4159 - auc: 0.3884 - val_loss: 0.6878 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7236\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6791 - tp: 83.0000 - fp: 30.0000 - tn: 83.0000 - fn: 30.0000 - accuracy: 0.7345 - precision: 0.7345 - recall: 0.7345 - auc: 0.7810 - val_loss: 0.6214 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7301\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5836 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.8906 - val_loss: 0.7198 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.5809\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3880 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9661 - val_loss: 1.4695 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4897\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2120 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9738 - val_loss: 2.8606 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5155\n",
      "Predict: [0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 1 1 1 1 1 0]\n",
      "True: [1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1]\n",
      "F1 score: 0.3508771929824561\n",
      "origin pos:23.0 neg:90.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7079 - tp: 118.0000 - fp: 52.0000 - tn: 118.0000 - fn: 52.0000 - accuracy: 0.6941 - precision: 0.6941 - recall: 0.6941 - auc: 0.6296 - val_loss: 0.6708 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.7535\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6813 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.8610 - val_loss: 0.6011 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.7516\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6208 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8956 - val_loss: 0.6007 - val_tp: 38.0000 - val_fp: 19.0000 - val_tn: 38.0000 - val_fn: 19.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7587\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.5305 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.9228 - val_loss: 0.6813 - val_tp: 35.0000 - val_fp: 22.0000 - val_tn: 35.0000 - val_fn: 22.0000 - val_accuracy: 0.6140 - val_precision: 0.6140 - val_recall: 0.6140 - val_auc: 0.7053\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2645 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9743 - val_loss: 1.4820 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.6787\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2552 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9704 - val_loss: 1.0483 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6774\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 0]\n",
      "F1 score: 0.16666666666666666\n",
      "Responsible\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.6933 - tp: 108.0000 - fp: 62.0000 - tn: 108.0000 - fn: 62.0000 - accuracy: 0.6353 - precision: 0.6353 - recall: 0.6353 - auc: 0.7018 - val_loss: 0.5010 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8495\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.7172 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9113 - val_loss: 0.6302 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8463\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6463 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9447 - val_loss: 0.5077 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.8418\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3728 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9892 - val_loss: 1.0470 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8615\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 1]\n",
      "F1 score: 0.2\n",
      "origin pos:20.0 neg:93.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.7139 - tp: 132.0000 - fp: 38.0000 - tn: 132.0000 - fn: 38.0000 - accuracy: 0.7765 - precision: 0.7765 - recall: 0.7765 - auc: 0.7954 - val_loss: 0.6566 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7110\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6846 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.8663 - val_loss: 0.6214 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7258\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5832 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9342 - val_loss: 0.6847 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.6805\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4777 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9507 - val_loss: 1.3256 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7618\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2325 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9512 - val_loss: 2.7820 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7765\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.0\n",
      "origin pos:22.0 neg:91.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 49ms/step - loss: 0.8042 - tp: 127.0000 - fp: 43.0000 - tn: 127.0000 - fn: 43.0000 - accuracy: 0.7471 - precision: 0.7471 - recall: 0.7471 - auc: 0.7614 - val_loss: 0.6788 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8483\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6884 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.8846 - val_loss: 0.6615 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8289\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6654 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8735 - val_loss: 0.5477 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8236\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5537 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9462 - val_loss: 0.6849 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8086\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4409 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9801 - val_loss: 1.0187 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.6580\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3198 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9623 - val_loss: 1.3861 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7861\n",
      "Predict: [0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0]\n",
      "True: [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0]\n",
      "F1 score: 0.0625\n",
      "Sociable\n",
      "origin pos:10.0 neg:103.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7864 - tp: 143.0000 - fp: 27.0000 - tn: 143.0000 - fn: 27.0000 - accuracy: 0.8412 - precision: 0.8412 - recall: 0.8412 - auc: 0.8337 - val_loss: 0.5670 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7679\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.7245 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9367 - val_loss: 0.6252 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7787\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6421 - tp: 105.0000 - fp: 8.0000 - tn: 105.0000 - fn: 8.0000 - accuracy: 0.9292 - precision: 0.9292 - recall: 0.9292 - auc: 0.9575 - val_loss: 0.6919 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7833\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4227 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9953 - val_loss: 1.1280 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.8070\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "True: [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.10526315789473685\n",
      "origin pos:21.0 neg:92.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 47ms/step - loss: 0.7670 - tp: 133.0000 - fp: 37.0000 - tn: 133.0000 - fn: 37.0000 - accuracy: 0.7824 - precision: 0.7824 - recall: 0.7824 - auc: 0.7882 - val_loss: 0.6282 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8775\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6852 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8640 - val_loss: 0.6588 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8797\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6192 - tp: 94.0000 - fp: 19.0000 - tn: 94.0000 - fn: 19.0000 - accuracy: 0.8319 - precision: 0.8319 - recall: 0.8319 - auc: 0.9265 - val_loss: 0.4225 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8680\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5825 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9195 - val_loss: 0.6381 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.6196\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4598 - tp: 96.0000 - fp: 17.0000 - tn: 96.0000 - fn: 17.0000 - accuracy: 0.8496 - precision: 0.8496 - recall: 0.8496 - auc: 0.9056 - val_loss: 0.7612 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8806\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3254 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9706 - val_loss: 0.8565 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.6033\n",
      "Predict: [0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 1]\n",
      "True: [1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0]\n",
      "F1 score: 0.2\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.7427 - tp: 130.0000 - fp: 40.0000 - tn: 130.0000 - fn: 40.0000 - accuracy: 0.7647 - precision: 0.7647 - recall: 0.7647 - auc: 0.7116 - val_loss: 0.6384 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8947\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.6721 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9148 - val_loss: 0.4967 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.9040\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5581 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9680 - val_loss: 0.4772 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.8680\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4232 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9911 - val_loss: 0.6599 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8495\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1965 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9857 - val_loss: 1.4244 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6531\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3275 - tp: 105.0000 - fp: 8.0000 - tn: 105.0000 - fn: 8.0000 - accuracy: 0.9292 - precision: 0.9292 - recall: 0.9292 - auc: 0.9593 - val_loss: 0.7944 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.7288\n",
      "Predict: [1 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0]\n",
      "F1 score: 0.2564102564102564\n",
      "Trustworthy\n",
      "origin pos:10.0 neg:103.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 1.1078 - tp: 140.0000 - fp: 30.0000 - tn: 140.0000 - fn: 30.0000 - accuracy: 0.8235 - precision: 0.8235 - recall: 0.8235 - auc: 0.8208 - val_loss: 0.5818 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.9018\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6708 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9612 - val_loss: 0.5656 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8981\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5929 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9668 - val_loss: 0.4309 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8846\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4313 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9954 - val_loss: 0.8369 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8578\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4392 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9930 - val_loss: 0.6186 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.8640\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4507 - tp: 111.0000 - fp: 2.0000 - tn: 111.0000 - fn: 2.0000 - accuracy: 0.9823 - precision: 0.9823 - recall: 0.9823 - auc: 0.9886 - val_loss: 0.5981 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8596\n",
      "Predict: [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.1\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 47ms/step - loss: 0.7057 - tp: 141.0000 - fp: 29.0000 - tn: 141.0000 - fn: 29.0000 - accuracy: 0.8294 - precision: 0.8294 - recall: 0.8294 - auc: 0.8228 - val_loss: 0.5690 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8633\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6829 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9286 - val_loss: 0.5439 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8732\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5146 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9678 - val_loss: 0.6069 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8541\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3545 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9908 - val_loss: 1.5737 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8473\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1719 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9597 - val_loss: 2.1212 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7870\n",
      "Predict: [0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1]\n",
      "True: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0]\n",
      "F1 score: 0.14814814814814814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin pos:13.0 neg:100.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.9025 - tp: 136.0000 - fp: 34.0000 - tn: 136.0000 - fn: 34.0000 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - auc: 0.8136 - val_loss: 0.6425 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8917\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6826 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9410 - val_loss: 0.6362 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.9012\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6064 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9586 - val_loss: 0.4003 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8987\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5087 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9751 - val_loss: 0.4607 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.8997\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4551 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9811 - val_loss: 0.5677 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8852\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3919 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9898 - val_loss: 0.5337 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8809\n",
      "Predict: [1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0]\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "f1_dict = dict()\n",
    "y_true_preds = dict()\n",
    "\n",
    "for label in labels:\n",
    "    y_raw = df[label]\n",
    "    y = tf.keras.utils.to_categorical(y_raw)\n",
    "    \n",
    "    f1_dict[label] = []\n",
    "    y_true_preds[label] = []\n",
    "    print(label)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):     \n",
    "        X_val_train, X_test = X[train_index], X[test_index]\n",
    "        y_val_train, y_test = y[train_index], y[test_index]\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_val_train, y_val_train, test_size=0.333, random_state=SEED)\n",
    "        \n",
    "        neg = y_train.sum(axis=0)[0]\n",
    "        pos = y_train.sum(axis=0)[1]\n",
    "        total = pos + neg\n",
    "        print(f\"origin pos:{pos} neg:{neg}\")\n",
    "\n",
    "        # クラスの重み\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "        model = get_binary_model()\n",
    "        \n",
    "        # 初期重みの最適化\n",
    "        initial_bias = np.log([neg/pos])\n",
    "        model.layers[-1].bias_initializer=initial_bias\n",
    "        \n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=METRICS)\n",
    "        es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='auto')\n",
    "        model.fit(X_train, y_train, batch_size=8, epochs=15, class_weight=class_weight, callbacks=[es_cb], validation_data=[X_val, y_val])\n",
    "        y_pred_tf = model.predict(X_test, batch_size=1)\n",
    "        y_pred = np.argmax(y_pred_tf, axis=1)\n",
    "        y_test_sk = np.argmax(y_test, axis=1)\n",
    "        print(\"Predict:\", y_pred)\n",
    "        print(\"True:\", y_test_sk)\n",
    "        f1 = f1_score(y_test_sk, y_pred, average=\"binary\")\n",
    "        print(\"F1 score:\", f1)\n",
    "        f1_dict[label].append(f1)\n",
    "        y_true_preds[label].append((y_test_sk, y_pred))\n",
    "        del model\n",
    "        gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51125f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2431372549019608"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL = 0\n",
    "cnt = 0\n",
    "for l in labels:\n",
    "    for k in range(3):\n",
    "        y_true, y_pred = y_true_preds[label][k]\n",
    "        HL += hamming_loss(y_true, y_pred)\n",
    "        cnt += 1\n",
    "HL /= cnt\n",
    "HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f44638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))\n",
    "macro_f1_val = np.mean(f1_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7699672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(f\"F1 score per label  (macro-f1: {macro_f1_val:.3f}, , Hamming Loss: {HL:.3f}, k=4)\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45111c2",
   "metadata": {},
   "source": [
    "### いろいろやってみてわかること\n",
    " - Predictを見るとわかるが，まったく学習できていない\n",
    " - 役に立たない　やはりデータが少なすぎるか\n",
    " - f1をlossに用いるほうが全然良い\n",
    " - macro-f1はf1の平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bf039",
   "metadata": {},
   "source": [
    "# マルチラベル問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97351565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_model():\n",
    "    input_ts = Input(shape=(512,))\n",
    "    dense1 = Dense(512, activation=\"relu\")(input_ts)\n",
    "    dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "    drop1 = Dropout(0.4, seed=SEED)(dense2)\n",
    "    dense3 = Dense(1024, activation=\"relu\")(drop1)\n",
    "    drop2 = Dropout(0.4, seed=SEED)(dense3)\n",
    "    dense4 = Dense(512, activation=\"relu\")(drop2)\n",
    "    dense5 = Dense(256, activation=\"relu\")(dense4)\n",
    "    dense6 = Dense(128, activation=\"relu\")(dense5)\n",
    "    drop3 = Dropout(0.2, seed=SEED)(dense6)\n",
    "    final = Dense(len(labels), activation=\"sigmoid\")(drop3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_ts],\n",
    "        outputs=[final]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e44ab02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f915e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_550 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,527,495\n",
      "Trainable params: 2,527,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38a8ea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Confident\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fb5ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.T[1:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1ddc464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 1., 0., 1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9131ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39., 126.,  57.,  66.,  45.,  36.,  31.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=0) # 各ラベルの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87fcabdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1fc6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = y.sum(axis=0) / len(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05146db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15294118, 0.49411765, 0.22352941, 0.25882353, 0.17647059,\n",
       "       0.14117647, 0.12156863])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c7dec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 0.5873 - acc: 0.2389 - val_loss: 0.5427 - val_acc: 0.3333\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4898 - acc: 0.3363 - val_loss: 0.5554 - val_acc: 0.3333\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4761 - acc: 0.1858 - val_loss: 0.5965 - val_acc: 0.3333\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4514 - acc: 0.3363 - val_loss: 0.5702 - val_acc: 0.3333\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5520 - acc: 0.4941\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.6062 - acc: 0.3363 - val_loss: 0.5486 - val_acc: 0.4386\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5320 - acc: 0.4248 - val_loss: 0.5412 - val_acc: 0.4386\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4833 - acc: 0.4159 - val_loss: 0.5899 - val_acc: 0.4386\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4506 - acc: 0.4248 - val_loss: 0.5872 - val_acc: 0.4386\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4316 - acc: 0.4248 - val_loss: 0.6037 - val_acc: 0.4386\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5257 - acc: 0.3882\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.5613 - acc: 0.3894 - val_loss: 0.4975 - val_acc: 0.4561\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5010 - acc: 0.3717 - val_loss: 0.4716 - val_acc: 0.4561\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4738 - acc: 0.4336 - val_loss: 0.4773 - val_acc: 0.4561\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4469 - acc: 0.4336 - val_loss: 0.4821 - val_acc: 0.4561\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4286 - acc: 0.4336 - val_loss: 0.4870 - val_acc: 0.4561\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5735 - acc: 0.3647\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "for train_index, test_index in kf.split(X):     \n",
    "    X_val_train, X_test = X[train_index], X[test_index]\n",
    "    y_val_train, y_test = y[train_index], y[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_val_train, y_val_train, test_size=0.333, random_state=SEED)\n",
    "\n",
    "    model = get_multi_model()\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='auto')\n",
    "    model.fit(X_train, y_train, batch_size=8, epochs=15,  callbacks=[es_cb], validation_data=[X_val, y_val])\n",
    "    model.evaluate(X_test,y_test)\n",
    "    y_pred = model.predict(X_test, batch_size=1)\n",
    "    y_preds.append(y_pred)\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e62ac759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.3504647 , 0.5133178 , 0.41513702, 0.40172338, 0.29465353,\n",
       "         0.23827103, 0.2787822 ],\n",
       "        [0.10067739, 0.5618096 , 0.24797939, 0.22042526, 0.04356267,\n",
       "         0.01720896, 0.03515984],\n",
       "        [0.12873566, 0.5511476 , 0.2649153 , 0.23839432, 0.06084595,\n",
       "         0.02660974, 0.05106943],\n",
       "        [0.17041212, 0.55062926, 0.31030235, 0.28979138, 0.09891968,\n",
       "         0.05334357, 0.08713944],\n",
       "        [0.14301263, 0.5656834 , 0.29003695, 0.2604343 , 0.07446929,\n",
       "         0.03587171, 0.06562696],\n",
       "        [0.31857163, 0.51682836, 0.39822397, 0.38329327, 0.25350705,\n",
       "         0.19303676, 0.23723665],\n",
       "        [0.04740989, 0.5989822 , 0.18341741, 0.1502343 , 0.01428592,\n",
       "         0.00399168, 0.01117025],\n",
       "        [0.20134366, 0.53491944, 0.32051727, 0.3043929 , 0.12299959,\n",
       "         0.07048188, 0.10877611],\n",
       "        [0.33054096, 0.51560605, 0.40657553, 0.39149052, 0.26918688,\n",
       "         0.21036232, 0.25219193],\n",
       "        [0.22988212, 0.5355606 , 0.34646422, 0.32603836, 0.15353568,\n",
       "         0.09535833, 0.139192  ],\n",
       "        [0.10068997, 0.56001705, 0.24742693, 0.22444707, 0.04379583,\n",
       "         0.01741073, 0.0352388 ],\n",
       "        [0.08648286, 0.5740479 , 0.23333514, 0.20433314, 0.03487217,\n",
       "         0.01292179, 0.02849411],\n",
       "        [0.13228263, 0.55588114, 0.27632278, 0.2524431 , 0.06702604,\n",
       "         0.03077553, 0.05640097],\n",
       "        [0.22645393, 0.5419163 , 0.35245022, 0.32591948, 0.15207082,\n",
       "         0.09444369, 0.139126  ],\n",
       "        [0.16172199, 0.54378355, 0.29445943, 0.2759883 , 0.08743904,\n",
       "         0.04480311, 0.07575505],\n",
       "        [0.13853778, 0.5626301 , 0.2971935 , 0.25938183, 0.07211939,\n",
       "         0.03431135, 0.06243604],\n",
       "        [0.19549285, 0.54062337, 0.324282  , 0.3074621 , 0.1221423 ,\n",
       "         0.0694377 , 0.10731456],\n",
       "        [0.30830526, 0.5187534 , 0.39208704, 0.37794238, 0.24226145,\n",
       "         0.1812647 , 0.22574703],\n",
       "        [0.07993279, 0.58121705, 0.22447959, 0.19631585, 0.03172226,\n",
       "         0.01126304, 0.02560228],\n",
       "        [0.22876981, 0.533422  , 0.34473312, 0.32608962, 0.15230522,\n",
       "         0.09511626, 0.13677745],\n",
       "        [0.28168494, 0.52292955, 0.37624195, 0.36043078, 0.20973559,\n",
       "         0.14818192, 0.19365229],\n",
       "        [0.13125134, 0.55223864, 0.27211088, 0.24857463, 0.06424203,\n",
       "         0.02904901, 0.05363234],\n",
       "        [0.06917281, 0.5781363 , 0.2108595 , 0.18578495, 0.02556571,\n",
       "         0.00854009, 0.02010802],\n",
       "        [0.35674363, 0.5148842 , 0.42343462, 0.40924382, 0.30452543,\n",
       "         0.2504097 , 0.29115102],\n",
       "        [0.16273521, 0.5422862 , 0.29057857, 0.27437204, 0.08898579,\n",
       "         0.04505267, 0.07652714],\n",
       "        [0.24783078, 0.52796304, 0.35094613, 0.3328713 , 0.16927135,\n",
       "         0.10954706, 0.15321335],\n",
       "        [0.31467348, 0.518276  , 0.3937424 , 0.37918335, 0.24836902,\n",
       "         0.18763766, 0.23307684],\n",
       "        [0.224453  , 0.53572404, 0.34716842, 0.32421023, 0.14877544,\n",
       "         0.09228404, 0.13437486],\n",
       "        [0.17123783, 0.55328   , 0.31690726, 0.28453243, 0.09895822,\n",
       "         0.05283958, 0.08854198],\n",
       "        [0.07518187, 0.56986636, 0.2197122 , 0.18987918, 0.02870128,\n",
       "         0.00970442, 0.02177599],\n",
       "        [0.08203606, 0.5741413 , 0.2270748 , 0.19525719, 0.03184804,\n",
       "         0.01111537, 0.02531035],\n",
       "        [0.20786606, 0.53957546, 0.33526668, 0.31840715, 0.13357736,\n",
       "         0.07965124, 0.11845449],\n",
       "        [0.27637845, 0.52717084, 0.37606514, 0.35613889, 0.20198058,\n",
       "         0.14145331, 0.18751106],\n",
       "        [0.17471543, 0.5433051 , 0.30637145, 0.28237212, 0.10055917,\n",
       "         0.05320193, 0.0868196 ],\n",
       "        [0.22654349, 0.5261296 , 0.3352212 , 0.31970456, 0.146901  ,\n",
       "         0.08990255, 0.13046679],\n",
       "        [0.16172452, 0.54614514, 0.2997046 , 0.27125886, 0.0889696 ,\n",
       "         0.04482518, 0.07561036],\n",
       "        [0.21399772, 0.5377171 , 0.34077337, 0.3223965 , 0.14045265,\n",
       "         0.08452684, 0.12465233],\n",
       "        [0.09490015, 0.5717724 , 0.24294509, 0.21884601, 0.04085147,\n",
       "         0.01592814, 0.03365317],\n",
       "        [0.17156224, 0.55255526, 0.30823874, 0.28267118, 0.09726939,\n",
       "         0.05113007, 0.08660507],\n",
       "        [0.16987516, 0.5452987 , 0.30428168, 0.28622204, 0.09695089,\n",
       "         0.05157786, 0.08462079],\n",
       "        [0.16712359, 0.546749  , 0.3070704 , 0.2804637 , 0.09204685,\n",
       "         0.04756727, 0.08014942],\n",
       "        [0.08949659, 0.5667135 , 0.23175383, 0.20674114, 0.03706435,\n",
       "         0.01384067, 0.02982031],\n",
       "        [0.1758188 , 0.5423633 , 0.31000212, 0.2873021 , 0.10080147,\n",
       "         0.0532413 , 0.08696955],\n",
       "        [0.06652526, 0.5885297 , 0.20948431, 0.17947863, 0.02399234,\n",
       "         0.00767833, 0.01944874],\n",
       "        [0.12980734, 0.5558719 , 0.27905223, 0.25523603, 0.06515512,\n",
       "         0.02975075, 0.05487659],\n",
       "        [0.27493116, 0.5276771 , 0.37436542, 0.35392103, 0.2032351 ,\n",
       "         0.14136033, 0.18895356],\n",
       "        [0.24540251, 0.5302571 , 0.36066636, 0.33909222, 0.170224  ,\n",
       "         0.11037552, 0.15491499],\n",
       "        [0.05749388, 0.57807875, 0.19337213, 0.16694556, 0.01920222,\n",
       "         0.00579252, 0.01426855],\n",
       "        [0.17993471, 0.5504307 , 0.31528386, 0.288503  , 0.10662222,\n",
       "         0.05775968, 0.09542374],\n",
       "        [0.15936759, 0.5447621 , 0.29707476, 0.27685943, 0.08759509,\n",
       "         0.04426647, 0.07500026],\n",
       "        [0.1500112 , 0.5611343 , 0.29311147, 0.26196945, 0.07867225,\n",
       "         0.03834414, 0.07007942],\n",
       "        [0.13334394, 0.56148106, 0.28709573, 0.25591344, 0.06739308,\n",
       "         0.031475  , 0.05828296],\n",
       "        [0.10039383, 0.57182527, 0.2478821 , 0.2145406 , 0.04439202,\n",
       "         0.01731247, 0.0358458 ],\n",
       "        [0.27253008, 0.5289748 , 0.3756966 , 0.35800126, 0.20181592,\n",
       "         0.14082827, 0.18613367],\n",
       "        [0.16529426, 0.5496083 , 0.30019373, 0.27952385, 0.09251408,\n",
       "         0.04790127, 0.08121331],\n",
       "        [0.26575434, 0.5329403 , 0.37336466, 0.35275397, 0.19136047,\n",
       "         0.13192734, 0.17805263],\n",
       "        [0.15085302, 0.5322134 , 0.27192098, 0.25774834, 0.07721376,\n",
       "         0.03684805, 0.06354132],\n",
       "        [0.28143162, 0.5230881 , 0.374284  , 0.3576288 , 0.20811026,\n",
       "         0.14639449, 0.19166286],\n",
       "        [0.12331189, 0.5663302 , 0.27595344, 0.24788351, 0.06048594,\n",
       "         0.02708605, 0.05167579],\n",
       "        [0.2900399 , 0.52096033, 0.38393316, 0.36879036, 0.22203606,\n",
       "         0.16012226, 0.20434844],\n",
       "        [0.2795491 , 0.5250584 , 0.3788683 , 0.36413935, 0.20961337,\n",
       "         0.14867762, 0.19355454],\n",
       "        [0.12949595, 0.55063885, 0.2668462 , 0.24278496, 0.06188404,\n",
       "         0.02760467, 0.05162168],\n",
       "        [0.26556987, 0.5276664 , 0.36646295, 0.3507371 , 0.19240774,\n",
       "         0.13136145, 0.17708187],\n",
       "        [0.23742975, 0.5333833 , 0.35891274, 0.33581704, 0.16262989,\n",
       "         0.10450072, 0.14800778],\n",
       "        [0.14590861, 0.5525488 , 0.28764486, 0.2646941 , 0.07676774,\n",
       "         0.03757324, 0.06603394],\n",
       "        [0.08266046, 0.571982  , 0.22468449, 0.20004037, 0.03171761,\n",
       "         0.01137857, 0.02567984],\n",
       "        [0.08454129, 0.58289176, 0.23702699, 0.20495059, 0.03414545,\n",
       "         0.01270193, 0.02876796],\n",
       "        [0.18246095, 0.5448306 , 0.31711242, 0.29037696, 0.10807227,\n",
       "         0.0590937 , 0.09560283],\n",
       "        [0.29744768, 0.52134734, 0.39099067, 0.37115684, 0.22921051,\n",
       "         0.16718012, 0.21349418],\n",
       "        [0.12438612, 0.55704   , 0.27706963, 0.2432359 , 0.05951907,\n",
       "         0.02628111, 0.04969598],\n",
       "        [0.17282566, 0.53713095, 0.30375576, 0.28240764, 0.09738586,\n",
       "         0.05081326, 0.08329151],\n",
       "        [0.26982296, 0.53086334, 0.3772315 , 0.35719723, 0.19903414,\n",
       "         0.13823998, 0.18552136],\n",
       "        [0.20763183, 0.53774416, 0.32929978, 0.30792725, 0.12863925,\n",
       "         0.0756177 , 0.11521073],\n",
       "        [0.15764365, 0.5533683 , 0.30427256, 0.2747079 , 0.08634025,\n",
       "         0.04364518, 0.07529519],\n",
       "        [0.05927482, 0.5948058 , 0.20204504, 0.17186283, 0.0207158 ,\n",
       "         0.00645752, 0.01683617],\n",
       "        [0.14924103, 0.55044276, 0.29421055, 0.26391438, 0.0803799 ,\n",
       "         0.03866937, 0.06764298],\n",
       "        [0.24819368, 0.5278126 , 0.35545447, 0.3341114 , 0.17182772,\n",
       "         0.11103662, 0.1566064 ],\n",
       "        [0.2432237 , 0.5288696 , 0.3529721 , 0.3383586 , 0.16820133,\n",
       "         0.10882276, 0.15146555],\n",
       "        [0.2874676 , 0.51967025, 0.37894505, 0.364579  , 0.21628965,\n",
       "         0.15483844, 0.19923243],\n",
       "        [0.10969024, 0.5637942 , 0.25551164, 0.22823925, 0.05013973,\n",
       "         0.02069055, 0.04152629],\n",
       "        [0.0918485 , 0.57695425, 0.24361105, 0.21649179, 0.03984325,\n",
       "         0.01535675, 0.03281065],\n",
       "        [0.13890098, 0.56541103, 0.28476304, 0.25798547, 0.0710942 ,\n",
       "         0.03366474, 0.06177201],\n",
       "        [0.13480227, 0.5513434 , 0.282685  , 0.2550927 , 0.06809145,\n",
       "         0.03138962, 0.05685572],\n",
       "        [0.28962368, 0.5274071 , 0.3841526 , 0.36562333, 0.22067326,\n",
       "         0.15918408, 0.20689473],\n",
       "        [0.2733759 , 0.5267198 , 0.3739846 , 0.35574627, 0.20303172,\n",
       "         0.14085463, 0.18675421]], dtype=float32),\n",
       " array([[3.79755311e-02, 6.27603531e-01, 1.65549457e-01, 2.28784978e-01,\n",
       "         5.19819744e-02, 4.98010293e-02, 2.22970098e-02],\n",
       "        [2.80029118e-01, 5.27144313e-01, 3.75709623e-01, 4.05489266e-01,\n",
       "         2.97703028e-01, 2.89909869e-01, 2.45362490e-01],\n",
       "        [1.95891380e-01, 5.43571770e-01, 3.22057962e-01, 3.60016584e-01,\n",
       "         2.16290563e-01, 2.10248977e-01, 1.58645689e-01],\n",
       "        [5.64144831e-03, 6.98155761e-01, 7.21534416e-02, 1.20405160e-01,\n",
       "         9.47568659e-03, 8.53136554e-03, 2.22833990e-03],\n",
       "        [3.46693862e-03, 6.90317214e-01, 5.28239533e-02, 9.54355001e-02,\n",
       "         6.02024188e-03, 5.62429940e-03, 1.30442088e-03],\n",
       "        [6.59868419e-02, 6.06451511e-01, 2.11224273e-01, 2.63976365e-01,\n",
       "         8.39297175e-02, 7.93693736e-02, 4.12376523e-02],\n",
       "        [2.22912565e-01, 5.43190002e-01, 3.41133595e-01, 3.72344255e-01,\n",
       "         2.40255713e-01, 2.33955905e-01, 1.83332309e-01],\n",
       "        [3.49245578e-01, 5.18816471e-01, 4.15560573e-01, 4.36691046e-01,\n",
       "         3.61991286e-01, 3.53385538e-01, 3.20989072e-01],\n",
       "        [2.15614811e-01, 5.42376101e-01, 3.36840540e-01, 3.71003956e-01,\n",
       "         2.36162469e-01, 2.27913305e-01, 1.77028105e-01],\n",
       "        [4.15663570e-01, 5.06462872e-01, 4.49299574e-01, 4.61056709e-01,\n",
       "         4.21665996e-01, 4.13462281e-01, 3.95910442e-01],\n",
       "        [2.70346999e-01, 5.26789188e-01, 3.69515449e-01, 3.99510562e-01,\n",
       "         2.89000839e-01, 2.81750441e-01, 2.36400276e-01],\n",
       "        [5.75348316e-03, 7.01084614e-01, 7.16531947e-02, 1.20586768e-01,\n",
       "         9.67606809e-03, 8.70725140e-03, 2.35466287e-03],\n",
       "        [3.79102200e-01, 5.11911035e-01, 4.29504514e-01, 4.46174741e-01,\n",
       "         3.87937874e-01, 3.80138755e-01, 3.55041087e-01],\n",
       "        [1.17982998e-01, 5.64152002e-01, 2.59447604e-01, 3.10705274e-01,\n",
       "         1.41382501e-01, 1.35870993e-01, 8.59521180e-02],\n",
       "        [2.72034891e-02, 6.31416678e-01, 1.42479271e-01, 1.96648404e-01,\n",
       "         3.81325819e-02, 3.59461047e-02, 1.48439314e-02],\n",
       "        [1.25901446e-01, 5.69580257e-01, 2.71039248e-01, 3.18842769e-01,\n",
       "         1.48118913e-01, 1.41869992e-01, 9.21560600e-02],\n",
       "        [3.29231471e-02, 6.11003458e-01, 1.48843318e-01, 2.09916845e-01,\n",
       "         4.54533249e-02, 4.41034399e-02, 1.90524496e-02],\n",
       "        [2.22731501e-01, 5.40976286e-01, 3.43460172e-01, 3.80329430e-01,\n",
       "         2.45082811e-01, 2.37638056e-01, 1.84664890e-01],\n",
       "        [1.67673945e-01, 5.58513701e-01, 3.04122537e-01, 3.42225045e-01,\n",
       "         1.90532237e-01, 1.80847570e-01, 1.28807202e-01],\n",
       "        [3.14670950e-01, 5.24384439e-01, 3.96670341e-01, 4.20709848e-01,\n",
       "         3.31452191e-01, 3.23313385e-01, 2.83284575e-01],\n",
       "        [3.77722412e-01, 5.12357414e-01, 4.29063112e-01, 4.47144359e-01,\n",
       "         3.86271745e-01, 3.78361195e-01, 3.52764964e-01],\n",
       "        [1.73304398e-02, 6.52854085e-01, 1.16703689e-01, 1.73477128e-01,\n",
       "         2.57519968e-02, 2.38908362e-02, 8.68208986e-03],\n",
       "        [2.98359878e-02, 6.28368318e-01, 1.47855207e-01, 2.06658468e-01,\n",
       "         4.21561040e-02, 3.97334024e-02, 1.65141467e-02],\n",
       "        [3.79133850e-01, 5.08753479e-01, 4.28405374e-01, 4.45442468e-01,\n",
       "         3.87875736e-01, 3.79036099e-01, 3.53356719e-01],\n",
       "        [2.22892404e-01, 5.44791043e-01, 3.43702435e-01, 3.74988884e-01,\n",
       "         2.43431985e-01, 2.33667627e-01, 1.82267517e-01],\n",
       "        [6.18676539e-04, 7.62579501e-01, 2.50368454e-02, 5.45437969e-02,\n",
       "         1.34539208e-03, 1.15358864e-03, 1.68896717e-04],\n",
       "        [9.87414196e-02, 5.78848541e-01, 2.43224144e-01, 2.95765400e-01,\n",
       "         1.18667156e-01, 1.13675743e-01, 6.95790723e-02],\n",
       "        [6.26482889e-02, 6.06184900e-01, 2.05074653e-01, 2.64082491e-01,\n",
       "         7.99409300e-02, 7.58054405e-02, 3.94770615e-02],\n",
       "        [3.43121309e-03, 6.99692547e-01, 5.49875572e-02, 1.03824250e-01,\n",
       "         6.36834232e-03, 5.84565243e-03, 1.33561459e-03],\n",
       "        [1.26885876e-01, 5.64274490e-01, 2.66378641e-01, 3.18365663e-01,\n",
       "         1.49274617e-01, 1.42298341e-01, 9.50671062e-02],\n",
       "        [4.92064096e-02, 6.12293184e-01, 1.82831496e-01, 2.34115303e-01,\n",
       "         6.41763210e-02, 5.90488687e-02, 2.89649684e-02],\n",
       "        [2.69872934e-01, 5.31525612e-01, 3.70094568e-01, 3.98561299e-01,\n",
       "         2.86273479e-01, 2.78857708e-01, 2.34046638e-01],\n",
       "        [3.08976293e-01, 5.22478640e-01, 3.91780138e-01, 4.15270895e-01,\n",
       "         3.22381914e-01, 3.15545291e-01, 2.75413334e-01],\n",
       "        [2.45608669e-02, 6.23617172e-01, 1.31987080e-01, 1.87616318e-01,\n",
       "         3.50189321e-02, 3.33170779e-02, 1.31237293e-02],\n",
       "        [1.73394278e-01, 5.51133275e-01, 3.05696815e-01, 3.51502717e-01,\n",
       "         1.98369741e-01, 1.90800011e-01, 1.38429239e-01],\n",
       "        [9.83764985e-05, 8.21127951e-01, 1.05459457e-02, 2.86525171e-02,\n",
       "         2.56884436e-04, 2.16372122e-04, 1.97129266e-05],\n",
       "        [1.37806060e-02, 6.39283597e-01, 1.02061003e-01, 1.61181495e-01,\n",
       "         2.17890367e-02, 2.04899944e-02, 6.84457785e-03],\n",
       "        [2.43545130e-01, 5.34254730e-01, 3.53480101e-01, 3.83055955e-01,\n",
       "         2.61297733e-01, 2.53399760e-01, 2.05564931e-01],\n",
       "        [3.74420613e-01, 5.13349593e-01, 4.28900510e-01, 4.46014434e-01,\n",
       "         3.83708298e-01, 3.75438929e-01, 3.48256916e-01],\n",
       "        [8.96490738e-02, 5.92118859e-01, 2.39786163e-01, 2.90572912e-01,\n",
       "         1.09497763e-01, 1.03585087e-01, 5.97105771e-02],\n",
       "        [1.60498414e-02, 6.41152263e-01, 1.09923534e-01, 1.67898551e-01,\n",
       "         2.46035010e-02, 2.34668534e-02, 8.09328258e-03],\n",
       "        [3.65842879e-01, 5.12047887e-01, 4.22800034e-01, 4.39908504e-01,\n",
       "         3.75105202e-01, 3.65725517e-01, 3.38207394e-01],\n",
       "        [4.19791579e-01, 5.03730118e-01, 4.49871778e-01, 4.62694466e-01,\n",
       "         4.24260616e-01, 4.16813970e-01, 4.01963323e-01],\n",
       "        [2.00314909e-01, 5.46488941e-01, 3.23656291e-01, 3.59816194e-01,\n",
       "         2.19394401e-01, 2.13274151e-01, 1.62853718e-01],\n",
       "        [1.23714805e-01, 5.59978127e-01, 2.64665216e-01, 3.15440953e-01,\n",
       "         1.47588909e-01, 1.45259529e-01, 9.29083824e-02],\n",
       "        [9.70172063e-02, 5.71891606e-01, 2.37760127e-01, 2.87379503e-01,\n",
       "         1.16831161e-01, 1.11038640e-01, 6.73305914e-02],\n",
       "        [3.68353655e-03, 7.18615294e-01, 5.98709434e-02, 1.04962952e-01,\n",
       "         6.52904436e-03, 5.85198821e-03, 1.35500985e-03],\n",
       "        [2.44433790e-01, 5.34430563e-01, 3.54983270e-01, 3.90893757e-01,\n",
       "         2.64721572e-01, 2.56890208e-01, 2.08227664e-01],\n",
       "        [4.55827087e-01, 5.00240922e-01, 4.68658745e-01, 4.76093262e-01,\n",
       "         4.57663029e-01, 4.49999124e-01, 4.42854494e-01],\n",
       "        [4.04429078e-01, 5.09154260e-01, 4.44033027e-01, 4.56586361e-01,\n",
       "         4.10579056e-01, 4.02204305e-01, 3.81794274e-01],\n",
       "        [1.52911350e-01, 5.51989019e-01, 2.88568079e-01, 3.31102759e-01,\n",
       "         1.74190834e-01, 1.66907400e-01, 1.16294272e-01],\n",
       "        [1.88678995e-01, 5.52671909e-01, 3.20014566e-01, 3.56267035e-01,\n",
       "         2.10098207e-01, 2.01533005e-01, 1.48977250e-01],\n",
       "        [1.28703251e-01, 5.68877459e-01, 2.73192048e-01, 3.20983052e-01,\n",
       "         1.49944246e-01, 1.44482777e-01, 9.41902101e-02],\n",
       "        [4.72784400e-01, 4.98379022e-01, 4.78616267e-01, 4.83385593e-01,\n",
       "         4.72640783e-01, 4.66029644e-01, 4.62501615e-01],\n",
       "        [1.61822796e-01, 5.61454713e-01, 3.02287728e-01, 3.40264320e-01,\n",
       "         1.83484554e-01, 1.76814482e-01, 1.23264894e-01],\n",
       "        [2.03688032e-04, 8.14006150e-01, 1.53592965e-02, 3.78032885e-02,\n",
       "         4.85755765e-04, 4.24385449e-04, 4.53176326e-05],\n",
       "        [5.34049459e-02, 6.05630279e-01, 1.91527322e-01, 2.50894487e-01,\n",
       "         7.03374520e-02, 6.55366629e-02, 3.25212926e-02],\n",
       "        [2.14110553e-01, 5.40162921e-01, 3.35548460e-01, 3.69112939e-01,\n",
       "         2.35245973e-01, 2.25513652e-01, 1.74993962e-01],\n",
       "        [1.64790124e-01, 5.61550438e-01, 3.06190521e-01, 3.44746977e-01,\n",
       "         1.87347293e-01, 1.78176463e-01, 1.25622153e-01],\n",
       "        [1.16489239e-01, 5.69013238e-01, 2.60604799e-01, 3.11857641e-01,\n",
       "         1.38165697e-01, 1.32392734e-01, 8.36500227e-02],\n",
       "        [3.46667737e-01, 5.16924322e-01, 4.13328379e-01, 4.34215605e-01,\n",
       "         3.57721269e-01, 3.50240827e-01, 3.17175388e-01],\n",
       "        [4.77650464e-02, 6.19509101e-01, 1.85385197e-01, 2.44113639e-01,\n",
       "         6.35813400e-02, 6.03334829e-02, 2.89622005e-02],\n",
       "        [7.04833493e-02, 5.90155959e-01, 2.11114302e-01, 2.65318960e-01,\n",
       "         9.05788019e-02, 8.57155919e-02, 4.62143235e-02],\n",
       "        [2.23151788e-01, 5.37357390e-01, 3.40047628e-01, 3.77030492e-01,\n",
       "         2.42287964e-01, 2.35320181e-01, 1.85171828e-01],\n",
       "        [2.95674443e-01, 5.23609579e-01, 3.83409262e-01, 4.10224199e-01,\n",
       "         3.10230672e-01, 3.02569240e-01, 2.61100620e-01],\n",
       "        [1.39629379e-01, 5.67486942e-01, 2.85472214e-01, 3.27836663e-01,\n",
       "         1.60885826e-01, 1.54280394e-01, 1.03268139e-01],\n",
       "        [5.03742509e-02, 6.03897095e-01, 1.81656927e-01, 2.42328271e-01,\n",
       "         6.58459887e-02, 6.26086071e-02, 3.12507749e-02],\n",
       "        [7.22415149e-02, 5.87988198e-01, 2.11576089e-01, 2.69044966e-01,\n",
       "         9.05922279e-02, 8.56942087e-02, 4.73202690e-02],\n",
       "        [2.32146177e-02, 6.38793707e-01, 1.33254007e-01, 1.90408841e-01,\n",
       "         3.38766985e-02, 3.11000571e-02, 1.22273071e-02],\n",
       "        [1.66890398e-01, 5.57104290e-01, 3.02051604e-01, 3.47318918e-01,\n",
       "         1.88219577e-01, 1.83988124e-01, 1.31613746e-01],\n",
       "        [7.37578496e-02, 6.03303075e-01, 2.18492702e-01, 2.75723398e-01,\n",
       "         9.35060084e-02, 8.90565366e-02, 4.85715047e-02],\n",
       "        [1.45963788e-01, 5.57191193e-01, 2.84409523e-01, 3.31758112e-01,\n",
       "         1.69568002e-01, 1.63120955e-01, 1.11657351e-01],\n",
       "        [6.48534074e-02, 5.98503590e-01, 2.05786332e-01, 2.59005934e-01,\n",
       "         8.24172795e-02, 7.67215565e-02, 4.13573533e-02],\n",
       "        [2.37912405e-02, 6.49861336e-01, 1.35661781e-01, 1.90314502e-01,\n",
       "         3.39253098e-02, 3.16868536e-02, 1.22215329e-02],\n",
       "        [2.09889114e-01, 5.46313226e-01, 3.34928244e-01, 3.69354606e-01,\n",
       "         2.29429230e-01, 2.20229119e-01, 1.70055836e-01],\n",
       "        [5.18944077e-02, 6.00509644e-01, 1.84949577e-01, 2.42321998e-01,\n",
       "         6.70624301e-02, 6.29771948e-02, 3.13936286e-02],\n",
       "        [4.08233069e-02, 6.08084261e-01, 1.65687218e-01, 2.20971957e-01,\n",
       "         5.52871414e-02, 5.32829575e-02, 2.40613278e-02],\n",
       "        [3.84930402e-01, 5.08890986e-01, 4.31534320e-01, 4.48694915e-01,\n",
       "         3.94159287e-01, 3.85635763e-01, 3.61235380e-01],\n",
       "        [1.18326306e-01, 5.70064247e-01, 2.63009995e-01, 3.11645240e-01,\n",
       "         1.40556470e-01, 1.33792669e-01, 8.49019513e-02],\n",
       "        [2.42712781e-01, 5.35254240e-01, 3.54324609e-01, 3.85069072e-01,\n",
       "         2.60449052e-01, 2.50962466e-01, 2.03142524e-01],\n",
       "        [1.99293792e-01, 5.48013151e-01, 3.26204598e-01, 3.68476629e-01,\n",
       "         2.20633581e-01, 2.13111684e-01, 1.61898062e-01],\n",
       "        [3.58129144e-01, 5.14422894e-01, 4.18224156e-01, 4.37321663e-01,\n",
       "         3.69008303e-01, 3.61328006e-01, 3.31272036e-01],\n",
       "        [2.69063622e-01, 5.30474007e-01, 3.69833440e-01, 3.98456514e-01,\n",
       "         2.85688192e-01, 2.76131123e-01, 2.31791586e-01],\n",
       "        [4.59439903e-01, 4.99392539e-01, 4.71222401e-01, 4.78143990e-01,\n",
       "         4.60554928e-01, 4.53333586e-01, 4.47116047e-01],\n",
       "        [2.51635522e-01, 5.32408655e-01, 3.57344925e-01, 3.82151037e-01,\n",
       "         2.67088324e-01, 2.60147065e-01, 2.12959334e-01]], dtype=float32),\n",
       " array([[0.3592105 , 0.50855625, 0.378976  , 0.38359421, 0.3953355 ,\n",
       "         0.34796777, 0.3126808 ],\n",
       "        [0.23450416, 0.5376583 , 0.26204008, 0.27956107, 0.28195336,\n",
       "         0.2147259 , 0.15483147],\n",
       "        [0.19172537, 0.5404746 , 0.21516079, 0.2443048 , 0.2414059 ,\n",
       "         0.17067732, 0.11166929],\n",
       "        [0.13745938, 0.5700698 , 0.15933125, 0.18384494, 0.18157315,\n",
       "         0.11569735, 0.06171182],\n",
       "        [0.06614018, 0.59933823, 0.09292593, 0.11116638, 0.10633119,\n",
       "         0.05422169, 0.02188586],\n",
       "        [0.2662022 , 0.52882725, 0.3015991 , 0.31052893, 0.31707487,\n",
       "         0.25327036, 0.2004103 ],\n",
       "        [0.22475424, 0.53524566, 0.24607548, 0.27229863, 0.27056244,\n",
       "         0.20352471, 0.14363562],\n",
       "        [0.2383707 , 0.53737503, 0.2574415 , 0.27847818, 0.28026778,\n",
       "         0.21455929, 0.15303698],\n",
       "        [0.2728596 , 0.5308977 , 0.30548865, 0.30979645, 0.31407276,\n",
       "         0.2578667 , 0.20257264],\n",
       "        [0.09872909, 0.5938085 , 0.12845567, 0.14393768, 0.14251974,\n",
       "         0.082197  , 0.03831222],\n",
       "        [0.15765876, 0.5616123 , 0.18817152, 0.20917042, 0.20358382,\n",
       "         0.13956937, 0.082344  ],\n",
       "        [0.42849827, 0.49207044, 0.4297705 , 0.43942297, 0.45410234,\n",
       "         0.41682428, 0.40429726],\n",
       "        [0.29871047, 0.5244476 , 0.3274116 , 0.33305162, 0.33998165,\n",
       "         0.28442192, 0.23369366],\n",
       "        [0.1129784 , 0.59338444, 0.14029641, 0.15557663, 0.15311268,\n",
       "         0.09450886, 0.04505274],\n",
       "        [0.10400998, 0.5793427 , 0.13010137, 0.15253463, 0.1508589 ,\n",
       "         0.0870499 , 0.04223052],\n",
       "        [0.27713937, 0.5327377 , 0.30109498, 0.31429487, 0.31806377,\n",
       "         0.2551393 , 0.20029454],\n",
       "        [0.13926555, 0.57822376, 0.16557458, 0.1821793 , 0.1807701 ,\n",
       "         0.11823077, 0.06278462],\n",
       "        [0.13550355, 0.56759006, 0.16812013, 0.18862136, 0.18402211,\n",
       "         0.11757667, 0.06650871],\n",
       "        [0.11832035, 0.57374495, 0.16437575, 0.17534624, 0.17196241,\n",
       "         0.10799275, 0.05967843],\n",
       "        [0.36658233, 0.50294787, 0.37841004, 0.3913256 , 0.4035739 ,\n",
       "         0.35250655, 0.32051757],\n",
       "        [0.03318644, 0.6450103 , 0.05337756, 0.06555711, 0.05948665,\n",
       "         0.0257029 , 0.00753636],\n",
       "        [0.32118413, 0.51341444, 0.34245953, 0.35506445, 0.36385977,\n",
       "         0.3071163 , 0.26212463],\n",
       "        [0.10548911, 0.5799683 , 0.14397968, 0.15787639, 0.1545779 ,\n",
       "         0.09306461, 0.0467044 ],\n",
       "        [0.14578569, 0.5613507 , 0.17501962, 0.19515815, 0.1979184 ,\n",
       "         0.12789406, 0.07336298],\n",
       "        [0.11850542, 0.55712897, 0.15129253, 0.18027268, 0.17136379,\n",
       "         0.10563893, 0.05752295],\n",
       "        [0.31062034, 0.5151496 , 0.32739812, 0.34168926, 0.3536688 ,\n",
       "         0.29214668, 0.24490072],\n",
       "        [0.1651449 , 0.5656986 , 0.19610716, 0.21624333, 0.20654508,\n",
       "         0.1430941 , 0.08697592],\n",
       "        [0.3263386 , 0.5133866 , 0.3388564 , 0.3575638 , 0.36431134,\n",
       "         0.3053745 , 0.2621261 ],\n",
       "        [0.10405941, 0.59557223, 0.14318429, 0.1527795 , 0.14572579,\n",
       "         0.08937906, 0.04404093],\n",
       "        [0.0723164 , 0.61447483, 0.10263377, 0.11266942, 0.10777669,\n",
       "         0.05922917, 0.02414755],\n",
       "        [0.29433674, 0.52683383, 0.3228653 , 0.3313612 , 0.33513263,\n",
       "         0.27818882, 0.22737989],\n",
       "        [0.26076782, 0.51916677, 0.2807874 , 0.30932298, 0.30957878,\n",
       "         0.24184707, 0.18787587],\n",
       "        [0.23853233, 0.53163964, 0.27273756, 0.28833762, 0.28659728,\n",
       "         0.2245843 , 0.16727929],\n",
       "        [0.28306046, 0.5290927 , 0.3122729 , 0.31907105, 0.32504287,\n",
       "         0.26615927, 0.2124288 ],\n",
       "        [0.17688605, 0.56172156, 0.20187564, 0.22030759, 0.21956626,\n",
       "         0.15315224, 0.09346836],\n",
       "        [0.13926555, 0.57822376, 0.16557458, 0.1821793 , 0.1807701 ,\n",
       "         0.11823077, 0.06278462],\n",
       "        [0.26063156, 0.53070205, 0.28556186, 0.3025614 , 0.30445752,\n",
       "         0.2400218 , 0.18473598],\n",
       "        [0.07626472, 0.60509205, 0.12058145, 0.12079197, 0.12150345,\n",
       "         0.06934292, 0.03007755],\n",
       "        [0.18584968, 0.5650234 , 0.21531618, 0.22745195, 0.22489108,\n",
       "         0.16344427, 0.10114455],\n",
       "        [0.11691218, 0.58549213, 0.14939061, 0.16403054, 0.16034734,\n",
       "         0.10085577, 0.05014113],\n",
       "        [0.05228225, 0.6263595 , 0.08802764, 0.09222618, 0.09019294,\n",
       "         0.04516493, 0.01689239],\n",
       "        [0.28728014, 0.51921344, 0.30631918, 0.3291484 , 0.33287042,\n",
       "         0.26729575, 0.2165134 ],\n",
       "        [0.19332781, 0.5394974 , 0.21934809, 0.24549651, 0.24513735,\n",
       "         0.17269431, 0.11587126],\n",
       "        [0.22406174, 0.5299803 , 0.2592923 , 0.2783979 , 0.28165776,\n",
       "         0.21032953, 0.15584975],\n",
       "        [0.3309726 , 0.519771  , 0.34315136, 0.3568595 , 0.36350805,\n",
       "         0.3099261 , 0.26270616],\n",
       "        [0.24780174, 0.530995  , 0.27490792, 0.29254246, 0.296213  ,\n",
       "         0.22755516, 0.17197855],\n",
       "        [0.23834252, 0.5365778 , 0.27121365, 0.28463793, 0.28894123,\n",
       "         0.22149965, 0.16418934],\n",
       "        [0.14339481, 0.5551866 , 0.17568177, 0.19803827, 0.20024501,\n",
       "         0.12622336, 0.07386404],\n",
       "        [0.13026308, 0.5757745 , 0.16375998, 0.1819053 , 0.17380653,\n",
       "         0.11369714, 0.0605723 ],\n",
       "        [0.08768804, 0.6030321 , 0.1143557 , 0.12839036, 0.12554441,\n",
       "         0.07115109, 0.03078101],\n",
       "        [0.24680346, 0.5338556 , 0.27431762, 0.29042417, 0.29491755,\n",
       "         0.22850718, 0.16974518],\n",
       "        [0.35752994, 0.5062985 , 0.36582604, 0.3827435 , 0.38985223,\n",
       "         0.33921453, 0.30234355],\n",
       "        [0.19977912, 0.5385695 , 0.22826687, 0.2542626 , 0.25379294,\n",
       "         0.17959481, 0.12370514],\n",
       "        [0.15523396, 0.5605734 , 0.18750001, 0.20506743, 0.20562524,\n",
       "         0.13693032, 0.08092378],\n",
       "        [0.18416879, 0.5396601 , 0.21115533, 0.23753427, 0.24312012,\n",
       "         0.16433111, 0.10944761],\n",
       "        [0.1841109 , 0.5558843 , 0.2298856 , 0.23443228, 0.23677044,\n",
       "         0.17206132, 0.11285093],\n",
       "        [0.18981728, 0.54457355, 0.23895732, 0.2443132 , 0.24513142,\n",
       "         0.18008189, 0.12369866],\n",
       "        [0.09135261, 0.59574986, 0.11750496, 0.13320439, 0.13296722,\n",
       "         0.07485432, 0.03320788],\n",
       "        [0.09120014, 0.5796266 , 0.11494597, 0.13954017, 0.13686894,\n",
       "         0.07620938, 0.03539973],\n",
       "        [0.10189184, 0.58001614, 0.13613825, 0.15419893, 0.148009  ,\n",
       "         0.08978654, 0.04398408],\n",
       "        [0.1491426 , 0.57395166, 0.1801031 , 0.19663183, 0.19355308,\n",
       "         0.12982543, 0.07235119],\n",
       "        [0.20536694, 0.5534439 , 0.23947188, 0.25150698, 0.25009203,\n",
       "         0.18504679, 0.12500007],\n",
       "        [0.1965622 , 0.54258   , 0.21738534, 0.24541648, 0.24743691,\n",
       "         0.17242378, 0.11394145],\n",
       "        [0.05010756, 0.63174564, 0.07865001, 0.08739869, 0.08252318,\n",
       "         0.04062418, 0.01428078],\n",
       "        [0.21283498, 0.5426773 , 0.23520947, 0.25540817, 0.2594832 ,\n",
       "         0.18880534, 0.12872267],\n",
       "        [0.24338184, 0.5263293 , 0.2634218 , 0.29107165, 0.29717198,\n",
       "         0.22119467, 0.16541778],\n",
       "        [0.17900988, 0.5609812 , 0.21978556, 0.22634391, 0.22907951,\n",
       "         0.16407847, 0.10440788],\n",
       "        [0.22203141, 0.5459319 , 0.25572777, 0.26594764, 0.26951   ,\n",
       "         0.20393167, 0.14348097],\n",
       "        [0.19840136, 0.5393611 , 0.23431776, 0.25441888, 0.25205195,\n",
       "         0.18360761, 0.12736647],\n",
       "        [0.17667358, 0.5564441 , 0.2032625 , 0.22247182, 0.22258309,\n",
       "         0.15390421, 0.09582236],\n",
       "        [0.3472677 , 0.5038268 , 0.35911605, 0.37721512, 0.38764176,\n",
       "         0.33175308, 0.29492122],\n",
       "        [0.14319721, 0.5712519 , 0.17012228, 0.1880805 , 0.18703254,\n",
       "         0.12309143, 0.06738587],\n",
       "        [0.07220703, 0.6063585 , 0.11972987, 0.11897459, 0.11942687,\n",
       "         0.0668315 , 0.02938423],\n",
       "        [0.18725409, 0.5504189 , 0.21299995, 0.23455851, 0.23113148,\n",
       "         0.1661112 , 0.10590528],\n",
       "        [0.13448606, 0.5652213 , 0.16194522, 0.18429779, 0.18747157,\n",
       "         0.11624102, 0.06358155],\n",
       "        [0.1006892 , 0.6057803 , 0.14268275, 0.14581998, 0.142086  ,\n",
       "         0.08804718, 0.04157973],\n",
       "        [0.16416404, 0.5769947 , 0.20011646, 0.20934214, 0.20585226,\n",
       "         0.1436671 , 0.08474444],\n",
       "        [0.05955175, 0.61186266, 0.09225836, 0.10408411, 0.09867699,\n",
       "         0.05050219, 0.02026148],\n",
       "        [0.07095058, 0.6029379 , 0.10685542, 0.11746358, 0.11508662,\n",
       "         0.06173397, 0.02635504],\n",
       "        [0.3828088 , 0.49882153, 0.38725397, 0.40287447, 0.41534564,\n",
       "         0.3658292 , 0.33754754],\n",
       "        [0.09361636, 0.5965348 , 0.13955292, 0.14325342, 0.13936818,\n",
       "         0.08472191, 0.04070278],\n",
       "        [0.04592662, 0.6463937 , 0.06991214, 0.07941667, 0.07427236,\n",
       "         0.0366763 , 0.01158273],\n",
       "        [0.13481943, 0.5734489 , 0.18489577, 0.1909891 , 0.18918748,\n",
       "         0.1255421 , 0.07210236],\n",
       "        [0.29472896, 0.5123478 , 0.31100056, 0.33624497, 0.34197754,\n",
       "         0.27561426, 0.2271473 ],\n",
       "        [0.04323513, 0.6450989 , 0.06428174, 0.07475924, 0.06959577,\n",
       "         0.03276104, 0.01019674]], dtype=float32)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e493d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_sk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a7c099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yp in y_preds:\n",
    "    y_preds_sk.append(np.where(yp > 0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25ae7b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_sk[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dbea810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "44402f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2257703081232493"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "hl = []\n",
    "for train_index, test_index in kf.split(X):     \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    l = hamming_loss(y_test, y_preds_sk[k])\n",
    "    hl.append(l)\n",
    "    k+=1\n",
    "HL = np.mean(hl)\n",
    "HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d4bebb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_dict = dict()\n",
    "for i,label in enumerate(labels):\n",
    "    f1_dict[label] = []\n",
    "    k = 0\n",
    "    for train_index, test_index in kf.split(X):     \n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_pred_label = y_preds_sk[k].T[i]\n",
    "        f1 = f1_score(y_test.T[i], y_pred_label, average=\"binary\")\n",
    "        f1_dict[label].append(f1)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d46f7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))\n",
    "macro_f1_val = np.mean(f1_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a6f0d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(f\"F1 score per label  (macro-f1: {macro_f1_val:.3f}, Hamming Loss: {HL:.3f}, k=4)\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a37fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8a6d970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), rate)\n",
    "plt.title(f\"そのラベルを持つ顔写真は全体の何割か\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427a231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
