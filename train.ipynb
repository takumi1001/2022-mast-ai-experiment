{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06fea3d",
   "metadata": {},
   "source": [
    "# 学習と評価\n",
    " - 二値分類モデルの並列を行い，マルチラベル問題を解く\n",
    " - FaceNetの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8fdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51b929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d712f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c978fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d763348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83471da0",
   "metadata": {},
   "source": [
    "## データのロード\n",
    "\n",
    "- 画像サイズは224×224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c4d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data1_union.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36eab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Caring</th>\n",
       "      <th>Confident</th>\n",
       "      <th>Emotionally stable</th>\n",
       "      <th>Intelligent</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Sociable</th>\n",
       "      <th>Trustworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>274783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>185955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>313100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>369866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>124821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>61202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Caring  Confident  Emotionally stable  Intelligent  Responsible  \\\n",
       "0     6269     1.0        0.0                 0.0          0.0          1.0   \n",
       "1   272998     1.0        1.0                 0.0          0.0          0.0   \n",
       "2   274783     1.0        1.0                 0.0          0.0          1.0   \n",
       "3   430823     0.0        1.0                 0.0          0.0          0.0   \n",
       "4   208848     0.0        0.0                 0.0          1.0          1.0   \n",
       "..     ...     ...        ...                 ...          ...          ...   \n",
       "80  185955     0.0        1.0                 1.0          1.0          1.0   \n",
       "81  313100     0.0        1.0                 0.0          0.0          0.0   \n",
       "82  369866     1.0        1.0                 0.0          1.0          1.0   \n",
       "83  124821     0.0        1.0                 1.0          1.0          0.0   \n",
       "84   61202     0.0        1.0                 1.0          1.0          0.0   \n",
       "\n",
       "    Sociable  Trustworthy  \n",
       "0        0.0          0.0  \n",
       "1        0.0          0.0  \n",
       "2        1.0          1.0  \n",
       "3        0.0          0.0  \n",
       "4        0.0          0.0  \n",
       "..       ...          ...  \n",
       "80       0.0          0.0  \n",
       "81       0.0          1.0  \n",
       "82       0.0          0.0  \n",
       "83       0.0          1.0  \n",
       "84       0.0          1.0  \n",
       "\n",
       "[85 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ecd64",
   "metadata": {},
   "source": [
    "## FaceNetで埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698ddb",
   "metadata": {},
   "source": [
    "メモ：```\\Lib\\site-packages\\facenet\\src\\facenet.py```の408行目をtensorflow v2仕様に書き換える必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbf47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_embedding import FaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8b7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: ../facenet//20180402-114759/20180402-114759.pb\n",
      "WARNING:tensorflow:From C:\\Users\\Owner\\python_venvs\\tensorflow\\lib\\site-packages\\facenet\\src\\facenet.py:407: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "FACE_MEDEL_PATH = '../facenet//20180402-114759/20180402-114759.pb'\n",
    "face_embedding = FaceEmbedding(FACE_MEDEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c6301e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_id in df[\"Id\"]:\n",
    "    path = f\"images/cleaned_20220519/{img_id}.jpg\"\n",
    "    face_vec = face_embedding.face_embeddings(path)[0]\n",
    "    X.append(face_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e77dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "147fc0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4ca29",
   "metadata": {},
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d63c3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPool2D, Lambda, Conv2D, Reshape, Input, RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016fb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_model(fine=False):\n",
    "    input_ts = Input(shape=(512,))\n",
    "    dense1 = Dense(512, activation=\"relu\")(input_ts)\n",
    "    dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "    drop1 = Dropout(0.4)(dense2)\n",
    "    dense3 = Dense(1024, activation=\"relu\")(drop1)\n",
    "    drop2 = Dropout(0.4)(dense3)\n",
    "    dense4 = Dense(512, activation=\"relu\")(drop2)\n",
    "    dense5 = Dense(256, activation=\"relu\")(dense4)\n",
    "    dense6 = Dense(128, activation=\"relu\")(dense5)\n",
    "    drop3 = Dropout(0.2)(dense6)\n",
    "    final = Dense(2, activation=\"softmax\")(drop3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_ts],\n",
    "        outputs=[final]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe2821",
   "metadata": {},
   "source": [
    "### まずは一つのラベルでテストする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずはconfidentでやってみる\n",
    "y_raw = df[\"Confident\"]\n",
    "y = tf.keras.utils.to_categorical(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4d25ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "158b5902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,526,850\n",
      "Trainable params: 2,526,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "565e1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02364838",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb8a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19ff1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1971dca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin pos:43.0 neg:13.0\n",
      "{0: 2.153846153846154, 1: 0.6511627906976745}\n",
      "Epoch 1/5\n",
      "56/56 [==============================] - 2s 11ms/step - loss: 0.6976 - tp: 37.0000 - fp: 19.0000 - tn: 37.0000 - fn: 19.0000 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - auc: 0.7310      \n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.7926 - tp: 43.0000 - fp: 13.0000 - tn: 43.0000 - fn: 13.0000 - accuracy: 0.7679 - precision: 0.7679 - recall: 0.7679 - auc: 0.8017\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5897 - tp: 51.0000 - fp: 5.0000 - tn: 51.0000 - fn: 5.0000 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - auc: 0.9196\n",
      "Epoch 4/5\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2244 - tp: 52.0000 - fp: 4.0000 - tn: 52.0000 - fn: 4.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9566 \n",
      "Epoch 5/5\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1621 - tp: 54.0000 - fp: 2.0000 - tn: 54.0000 - fn: 2.0000 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9751\n",
      "Predict: [1 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1]\n",
      "True: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1]\n",
      "F1 score: 0.7000000000000001\n",
      "29/29 [==============================] - 1s 5ms/step - loss: 3.9832 - tp: 17.0000 - fp: 12.0000 - tn: 17.0000 - fn: 12.0000 - accuracy: 0.5862 - precision: 0.5862 - recall: 0.5862 - auc: 0.5719   \n",
      "origin pos:42.0 neg:15.0\n",
      "{0: 1.9, 1: 0.6785714285714285}\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 1.3816 - tp: 32.0000 - fp: 25.0000 - tn: 32.0000 - fn: 25.0000 - accuracy: 0.5614 - precision: 0.5614 - recall: 0.5614 - auc: 0.6106\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7499 - tp: 40.0000 - fp: 17.0000 - tn: 40.0000 - fn: 17.0000 - accuracy: 0.7018 - precision: 0.7018 - recall: 0.7018 - auc: 0.8056         \n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.6233 - tp: 45.0000 - fp: 12.0000 - tn: 45.0000 - fn: 12.0000 - accuracy: 0.7895 - precision: 0.7895 - recall: 0.7895 - auc: 0.8630\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.4717 - tp: 41.0000 - fp: 16.0000 - tn: 41.0000 - fn: 16.0000 - accuracy: 0.7193 - precision: 0.7193 - recall: 0.7193 - auc: 0.8012\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.3020 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9391\n",
      "Predict: [1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1]\n",
      "True: [0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "F1 score: 0.9333333333333332\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3405 - tp: 25.0000 - fp: 3.0000 - tn: 25.0000 - fn: 3.0000 - accuracy: 0.8929 - precision: 0.8929 - recall: 0.8929 - auc: 0.9126                \n",
      "origin pos:45.0 neg:12.0\n",
      "{0: 2.375, 1: 0.6333333333333333}\n",
      "Epoch 1/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.7223 - tp: 46.0000 - fp: 11.0000 - tn: 46.0000 - fn: 11.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.8830\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.2392 - tp: 51.0000 - fp: 6.0000 - tn: 51.0000 - fn: 6.0000 - accuracy: 0.8947 - precision: 0.8947 - recall: 0.8947 - auc: 0.9615\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0845 - tp: 56.0000 - fp: 1.0000 - tn: 56.0000 - fn: 1.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9991    \n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.1764 - tp: 53.0000 - fp: 4.0000 - tn: 53.0000 - fn: 4.0000 - accuracy: 0.9298 - precision: 0.9298 - recall: 0.9298 - auc: 0.9757\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0200 - tp: 57.0000 - fp: 0.0000e+00 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Predict: [1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 1 1]\n",
      "True: [1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1]\n",
      "F1 score: 0.9500000000000001\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1646 - tp: 26.0000 - fp: 2.0000 - tn: 26.0000 - fn: 2.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9949    \n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "f1s = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    y_test_sk = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    neg = y_train.sum(axis=0)[0]\n",
    "    pos = y_train.sum(axis=0)[1]\n",
    "    total = pos + neg\n",
    "    print(f\"origin pos:{pos} neg:{neg}\")\n",
    "    \n",
    "    \n",
    "    # 初期重みの最適化\n",
    "    initial_bias = np.log([neg/pos])\n",
    "    model.layers[-1].bias_initializer=initial_bias\n",
    "    \n",
    "    # クラスの重み\n",
    "    weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "    weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    print(class_weight)\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, batch_size=1, epochs=5, class_weight=class_weight)\n",
    "    y_pred = np.argmax(model.predict(X_test, batch_size=1), axis=1)\n",
    "    print(\"Predict:\", y_pred)\n",
    "    print(\"True:\", y_test_sk)\n",
    "    f1 = f1_score(y_test_sk, y_pred, average=\"binary\")\n",
    "    print(\"F1 score:\", f1)\n",
    "    f1s.append(f1)\n",
    "    accs.append(model.evaluate(X_test, y_test, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c46a44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8efe50",
   "metadata": {},
   "source": [
    "## すべてのラベルでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "449383e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Caring\",\"Confident\",\"Emotionally stable\",\"Intelligent\",\"Responsible\",\"Sociable\",\"Trustworthy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e9da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b530f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caring\n",
      "origin pos:21.0 neg:35.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 24ms/step - loss: 0.7006 - tp: 75.0000 - fp: 38.0000 - tn: 75.0000 - fn: 38.0000 - accuracy: 0.6637 - precision: 0.6637 - recall: 0.6637 - auc: 0.8162\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6930 - tp: 34.0000 - fp: 22.0000 - tn: 34.0000 - fn: 22.0000 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - auc: 0.6130\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6566 - tp: 35.0000 - fp: 21.0000 - tn: 35.0000 - fn: 21.0000 - accuracy: 0.6250 - precision: 0.6250 - recall: 0.6250 - auc: 0.7278\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5170 - tp: 45.0000 - fp: 11.0000 - tn: 45.0000 - fn: 11.0000 - accuracy: 0.8036 - precision: 0.8036 - recall: 0.8036 - auc: 0.8836\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3200 - tp: 46.0000 - fp: 10.0000 - tn: 46.0000 - fn: 10.0000 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - auc: 0.9324\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1160 - tp: 53.0000 - fp: 3.0000 - tn: 53.0000 - fn: 3.0000 - accuracy: 0.9464 - precision: 0.9464 - recall: 0.9464 - auc: 0.9770  \n",
      "Predict: [0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1]\n",
      "True: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "F1 score: 0.2222222222222222\n",
      "origin pos:17.0 neg:40.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.6950 - tp: 80.0000 - fp: 33.0000 - tn: 80.0000 - fn: 33.0000 - accuracy: 0.7080 - precision: 0.7080 - recall: 0.7080 - auc: 0.8447\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7086 - tp: 40.0000 - fp: 17.0000 - tn: 40.0000 - fn: 17.0000 - accuracy: 0.7018 - precision: 0.7018 - recall: 0.7018 - auc: 0.7021\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6701 - tp: 40.0000 - fp: 17.0000 - tn: 40.0000 - fn: 17.0000 - accuracy: 0.7018 - precision: 0.7018 - recall: 0.7018 - auc: 0.7999\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5044 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9557\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2394 - tp: 53.0000 - fp: 4.0000 - tn: 53.0000 - fn: 4.0000 - accuracy: 0.9298 - precision: 0.9298 - recall: 0.9298 - auc: 0.9769 \n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0975 - tp: 55.0000 - fp: 2.0000 - tn: 55.0000 - fn: 2.0000 - accuracy: 0.9649 - precision: 0.9649 - recall: 0.9649 - auc: 0.9969\n",
      "Predict: [0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "True: [1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "F1 score: 0.13333333333333333\n",
      "origin pos:14.0 neg:43.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 12ms/step - loss: 0.7047 - tp: 92.0000 - fp: 22.0000 - tn: 92.0000 - fn: 22.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.8961\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6970 - tp: 43.0000 - fp: 14.0000 - tn: 43.0000 - fn: 14.0000 - accuracy: 0.7544 - precision: 0.7544 - recall: 0.7544 - auc: 0.7590\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.7056 - tp: 43.0000 - fp: 14.0000 - tn: 43.0000 - fn: 14.0000 - accuracy: 0.7544 - precision: 0.7544 - recall: 0.7544 - auc: 0.7821\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6360 - tp: 43.0000 - fp: 14.0000 - tn: 43.0000 - fn: 14.0000 - accuracy: 0.7544 - precision: 0.7544 - recall: 0.7544 - auc: 0.8750\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4460 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9700 \n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3242 - tp: 55.0000 - fp: 2.0000 - tn: 55.0000 - fn: 2.0000 - accuracy: 0.9649 - precision: 0.9649 - recall: 0.9649 - auc: 0.9886 \n",
      "Predict: [0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "True: [1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
      "F1 score: 0.5\n",
      "Confident\n",
      "origin pos:43.0 neg:13.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 6ms/step - loss: 0.7091 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.8996\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6746 - tp: 43.0000 - fp: 13.0000 - tn: 43.0000 - fn: 13.0000 - accuracy: 0.7679 - precision: 0.7679 - recall: 0.7679 - auc: 0.8552\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5362 - tp: 43.0000 - fp: 13.0000 - tn: 43.0000 - fn: 13.0000 - accuracy: 0.7679 - precision: 0.7679 - recall: 0.7679 - auc: 0.9407\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4172 - tp: 48.0000 - fp: 8.0000 - tn: 48.0000 - fn: 8.0000 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - auc: 0.9664\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3348 - tp: 56.0000 - fp: 0.0000e+00 - tn: 56.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2623 - tp: 55.0000 - fp: 1.0000 - tn: 55.0000 - fn: 1.0000 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - auc: 0.9968\n",
      "Predict: [1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1]\n",
      "True: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1]\n",
      "F1 score: 0.7272727272727273\n",
      "origin pos:42.0 neg:15.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 0.6991 - tp: 94.0000 - fp: 19.0000 - tn: 94.0000 - fn: 19.0000 - accuracy: 0.8319 - precision: 0.8319 - recall: 0.8319 - auc: 0.9148\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6916 - tp: 42.0000 - fp: 15.0000 - tn: 42.0000 - fn: 15.0000 - accuracy: 0.7368 - precision: 0.7368 - recall: 0.7368 - auc: 0.8015\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6569 - tp: 42.0000 - fp: 15.0000 - tn: 42.0000 - fn: 15.0000 - accuracy: 0.7368 - precision: 0.7368 - recall: 0.7368 - auc: 0.8766\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5329 - tp: 46.0000 - fp: 11.0000 - tn: 46.0000 - fn: 11.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.9217\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3483 - tp: 57.0000 - fp: 0.0000e+00 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1454 - tp: 57.0000 - fp: 0.0000e+00 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Predict: [1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1]\n",
      "True: [0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "F1 score: 0.6829268292682927\n",
      "origin pos:45.0 neg:12.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 9ms/step - loss: 0.6991 - tp: 95.0000 - fp: 19.0000 - tn: 95.0000 - fn: 19.0000 - accuracy: 0.8333 - precision: 0.8333 - recall: 0.8333 - auc: 0.9342\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7017 - tp: 45.0000 - fp: 12.0000 - tn: 45.0000 - fn: 12.0000 - accuracy: 0.7895 - precision: 0.7895 - recall: 0.7895 - auc: 0.8163\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6676 - tp: 45.0000 - fp: 12.0000 - tn: 45.0000 - fn: 12.0000 - accuracy: 0.7895 - precision: 0.7895 - recall: 0.7895 - auc: 0.8960\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5376 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9645\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3677 - tp: 54.0000 - fp: 3.0000 - tn: 54.0000 - fn: 3.0000 - accuracy: 0.9474 - precision: 0.9474 - recall: 0.9474 - auc: 0.9942\n",
      "Epoch 6/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1022 - tp: 57.0000 - fp: 0.0000e+00 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Predict: [1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "True: [1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1]\n",
      "F1 score: 0.7826086956521738\n",
      "Emotionally stable\n",
      "origin pos:16.0 neg:40.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 11ms/step - loss: 0.6967 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.9070\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6974 - tp: 40.0000 - fp: 16.0000 - tn: 40.0000 - fn: 16.0000 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - auc: 0.7146\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6667 - tp: 40.0000 - fp: 16.0000 - tn: 40.0000 - fn: 16.0000 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - auc: 0.8181\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5388 - tp: 47.0000 - fp: 9.0000 - tn: 47.0000 - fn: 9.0000 - accuracy: 0.8393 - precision: 0.8393 - recall: 0.8393 - auc: 0.9085\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2665 - tp: 54.0000 - fp: 2.0000 - tn: 54.0000 - fn: 2.0000 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9662  \n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0653 - tp: 55.0000 - fp: 1.0000 - tn: 55.0000 - fn: 1.0000 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - auc: 0.9997  \n",
      "Predict: [0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0]\n",
      "True: [0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1]\n",
      "F1 score: 0.27272727272727276\n",
      "origin pos:23.0 neg:34.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.6946 - tp: 79.0000 - fp: 34.0000 - tn: 79.0000 - fn: 34.0000 - accuracy: 0.6991 - precision: 0.6991 - recall: 0.6991 - auc: 0.8431\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6866 - tp: 29.0000 - fp: 28.0000 - tn: 29.0000 - fn: 28.0000 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - auc: 0.5309\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6972 - tp: 35.0000 - fp: 22.0000 - tn: 35.0000 - fn: 22.0000 - accuracy: 0.6140 - precision: 0.6140 - recall: 0.6140 - auc: 0.6328\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5837 - tp: 40.0000 - fp: 17.0000 - tn: 40.0000 - fn: 17.0000 - accuracy: 0.7018 - precision: 0.7018 - recall: 0.7018 - auc: 0.7649\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3785 - tp: 50.0000 - fp: 7.0000 - tn: 50.0000 - fn: 7.0000 - accuracy: 0.8772 - precision: 0.8772 - recall: 0.8772 - auc: 0.9110\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2014 - tp: 53.0000 - fp: 4.0000 - tn: 53.0000 - fn: 4.0000 - accuracy: 0.9298 - precision: 0.9298 - recall: 0.9298 - auc: 0.9837\n",
      "Predict: [1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1]\n",
      "True: [0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "F1 score: 0.3846153846153846\n",
      "origin pos:19.0 neg:38.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 0.6958 - tp: 76.0000 - fp: 38.0000 - tn: 76.0000 - fn: 38.0000 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - auc: 0.8196\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6840 - tp: 38.0000 - fp: 19.0000 - tn: 38.0000 - fn: 19.0000 - accuracy: 0.6667 - precision: 0.6667 - recall: 0.6667 - auc: 0.7038\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6141 - tp: 31.0000 - fp: 26.0000 - tn: 31.0000 - fn: 26.0000 - accuracy: 0.5439 - precision: 0.5439 - recall: 0.5439 - auc: 0.6637\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4258 - tp: 48.0000 - fp: 9.0000 - tn: 48.0000 - fn: 9.0000 - accuracy: 0.8421 - precision: 0.8421 - recall: 0.8421 - auc: 0.9178\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5014 - tp: 50.0000 - fp: 7.0000 - tn: 50.0000 - fn: 7.0000 - accuracy: 0.8772 - precision: 0.8772 - recall: 0.8772 - auc: 0.8883\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1840 - tp: 56.0000 - fp: 1.0000 - tn: 56.0000 - fn: 1.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9954 \n",
      "Predict: [0 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0]\n",
      "True: [0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1]\n",
      "F1 score: 0.2727272727272727\n",
      "Intelligent\n",
      "origin pos:35.0 neg:21.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 7ms/step - loss: 0.7049 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.8774\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6931 - tp: 30.0000 - fp: 26.0000 - tn: 30.0000 - fn: 26.0000 - accuracy: 0.5357 - precision: 0.5357 - recall: 0.5357 - auc: 0.6205\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6657 - tp: 40.0000 - fp: 16.0000 - tn: 40.0000 - fn: 16.0000 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - auc: 0.8104\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5472 - tp: 46.0000 - fp: 10.0000 - tn: 46.0000 - fn: 10.0000 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - auc: 0.8760\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2320 - tp: 53.0000 - fp: 3.0000 - tn: 53.0000 - fn: 3.0000 - accuracy: 0.9464 - precision: 0.9464 - recall: 0.9464 - auc: 0.9726  \n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1146 - tp: 54.0000 - fp: 2.0000 - tn: 54.0000 - fn: 2.0000 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9796  \n",
      "Predict: [1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1]\n",
      "True: [0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1]\n",
      "F1 score: 0.5789473684210527\n",
      "origin pos:33.0 neg:24.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 0.6928 - tp: 80.0000 - fp: 33.0000 - tn: 80.0000 - fn: 33.0000 - accuracy: 0.7080 - precision: 0.7080 - recall: 0.7080 - auc: 0.8341\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7019 - tp: 31.0000 - fp: 26.0000 - tn: 31.0000 - fn: 26.0000 - accuracy: 0.5439 - precision: 0.5439 - recall: 0.5439 - auc: 0.5263\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6835 - tp: 31.0000 - fp: 26.0000 - tn: 31.0000 - fn: 26.0000 - accuracy: 0.5439 - precision: 0.5439 - recall: 0.5439 - auc: 0.5813\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6171 - tp: 41.0000 - fp: 16.0000 - tn: 41.0000 - fn: 16.0000 - accuracy: 0.7193 - precision: 0.7193 - recall: 0.7193 - auc: 0.7930\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4854 - tp: 46.0000 - fp: 11.0000 - tn: 46.0000 - fn: 11.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.8524\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1963 - tp: 54.0000 - fp: 3.0000 - tn: 54.0000 - fn: 3.0000 - accuracy: 0.9474 - precision: 0.9474 - recall: 0.9474 - auc: 0.9877\n",
      "Predict: [1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0]\n",
      "True: [0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1]\n",
      "F1 score: 0.6486486486486486\n",
      "origin pos:32.0 neg:25.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.6991 - tp: 74.0000 - fp: 40.0000 - tn: 74.0000 - fn: 40.0000 - accuracy: 0.6491 - precision: 0.6491 - recall: 0.6491 - auc: 0.7993\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6916 - tp: 31.0000 - fp: 26.0000 - tn: 31.0000 - fn: 26.0000 - accuracy: 0.5439 - precision: 0.5439 - recall: 0.5439 - auc: 0.5414\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6853 - tp: 25.0000 - fp: 32.0000 - tn: 25.0000 - fn: 32.0000 - accuracy: 0.4386 - precision: 0.4386 - recall: 0.4386 - auc: 0.5297\n",
      "Epoch 4/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6508 - tp: 27.0000 - fp: 30.0000 - tn: 27.0000 - fn: 30.0000 - accuracy: 0.4737 - precision: 0.4737 - recall: 0.4737 - auc: 0.6014\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5079 - tp: 49.0000 - fp: 8.0000 - tn: 49.0000 - fn: 8.0000 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - auc: 0.9412\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4928 - tp: 44.0000 - fp: 13.0000 - tn: 44.0000 - fn: 13.0000 - accuracy: 0.7719 - precision: 0.7719 - recall: 0.7719 - auc: 0.8406\n",
      "Predict: [0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 1]\n",
      "True: [0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1]\n",
      "F1 score: 0.4848484848484848\n",
      "Responsible\n",
      "origin pos:25.0 neg:31.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 13ms/step - loss: 0.6922 - tp: 71.0000 - fp: 42.0000 - tn: 71.0000 - fn: 42.0000 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - auc: 0.7302\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6565 - tp: 37.0000 - fp: 19.0000 - tn: 37.0000 - fn: 19.0000 - accuracy: 0.6607 - precision: 0.6607 - recall: 0.6607 - auc: 0.7918\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4538 - tp: 48.0000 - fp: 8.0000 - tn: 48.0000 - fn: 8.0000 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - auc: 0.9171\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1487 - tp: 52.0000 - fp: 4.0000 - tn: 52.0000 - fn: 4.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9876\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1137 - tp: 55.0000 - fp: 1.0000 - tn: 55.0000 - fn: 1.0000 - accuracy: 0.9821 - precision: 0.9821 - recall: 0.9821 - auc: 0.9809  \n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1799 - tp: 54.0000 - fp: 2.0000 - tn: 54.0000 - fn: 2.0000 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - auc: 0.9802  \n",
      "Predict: [0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0]\n",
      "True: [1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1]\n",
      "F1 score: 0.25\n",
      "origin pos:28.0 neg:29.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.6950 - tp: 82.0000 - fp: 31.0000 - tn: 82.0000 - fn: 31.0000 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - auc: 0.8357\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6910 - tp: 32.0000 - fp: 25.0000 - tn: 32.0000 - fn: 25.0000 - accuracy: 0.5614 - precision: 0.5614 - recall: 0.5614 - auc: 0.5823\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6607 - tp: 39.0000 - fp: 18.0000 - tn: 39.0000 - fn: 18.0000 - accuracy: 0.6842 - precision: 0.6842 - recall: 0.6842 - auc: 0.7936\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5543 - tp: 46.0000 - fp: 11.0000 - tn: 46.0000 - fn: 11.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.8187\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4423 - tp: 49.0000 - fp: 8.0000 - tn: 49.0000 - fn: 8.0000 - accuracy: 0.8596 - precision: 0.8596 - recall: 0.8596 - auc: 0.8732\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1422 - tp: 54.0000 - fp: 3.0000 - tn: 54.0000 - fn: 3.0000 - accuracy: 0.9474 - precision: 0.9474 - recall: 0.9474 - auc: 0.9923\n",
      "Predict: [0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0]\n",
      "True: [1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1]\n",
      "F1 score: 0.6363636363636364\n",
      "origin pos:29.0 neg:28.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 12ms/step - loss: 0.6928 - tp: 85.0000 - fp: 29.0000 - tn: 85.0000 - fn: 29.0000 - accuracy: 0.7456 - precision: 0.7456 - recall: 0.7456 - auc: 0.8475\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6923 - tp: 33.0000 - fp: 24.0000 - tn: 33.0000 - fn: 24.0000 - accuracy: 0.5789 - precision: 0.5789 - recall: 0.5789 - auc: 0.5462\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5497 - tp: 46.0000 - fp: 11.0000 - tn: 46.0000 - fn: 11.0000 - accuracy: 0.8070 - precision: 0.8070 - recall: 0.8070 - auc: 0.8935\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3947 - tp: 48.0000 - fp: 9.0000 - tn: 48.0000 - fn: 9.0000 - accuracy: 0.8421 - precision: 0.8421 - recall: 0.8421 - auc: 0.8954\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1997 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9677\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1162 - tp: 55.0000 - fp: 2.0000 - tn: 55.0000 - fn: 2.0000 - accuracy: 0.9649 - precision: 0.9649 - recall: 0.9649 - auc: 0.9800 \n",
      "Predict: [0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0]\n",
      "True: [0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      "F1 score: 0.2727272727272727\n",
      "Sociable\n",
      "origin pos:16.0 neg:40.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 7ms/step - loss: 0.6977 - tp: 89.0000 - fp: 24.0000 - tn: 89.0000 - fn: 24.0000 - accuracy: 0.7876 - precision: 0.7876 - recall: 0.7876 - auc: 0.8953\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6862 - tp: 40.0000 - fp: 16.0000 - tn: 40.0000 - fn: 16.0000 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - auc: 0.7765\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6375 - tp: 41.0000 - fp: 15.0000 - tn: 41.0000 - fn: 15.0000 - accuracy: 0.7321 - precision: 0.7321 - recall: 0.7321 - auc: 0.8543\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4004 - tp: 52.0000 - fp: 4.0000 - tn: 52.0000 - fn: 4.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9770  \n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2630 - tp: 52.0000 - fp: 4.0000 - tn: 52.0000 - fn: 4.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9672  \n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5952 - tp: 47.0000 - fp: 9.0000 - tn: 47.0000 - fn: 9.0000 - accuracy: 0.8393 - precision: 0.8393 - recall: 0.8393 - auc: 0.8575\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0]\n",
      "F1 score: 0.0\n",
      "origin pos:24.0 neg:33.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 12ms/step - loss: 0.6983 - tp: 73.0000 - fp: 40.0000 - tn: 73.0000 - fn: 40.0000 - accuracy: 0.6460 - precision: 0.6460 - recall: 0.6460 - auc: 0.7457\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6929 - tp: 33.0000 - fp: 24.0000 - tn: 33.0000 - fn: 24.0000 - accuracy: 0.5789 - precision: 0.5789 - recall: 0.5789 - auc: 0.6106\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6918 - tp: 33.0000 - fp: 24.0000 - tn: 33.0000 - fn: 24.0000 - accuracy: 0.5789 - precision: 0.5789 - recall: 0.5789 - auc: 0.6599\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6137 - tp: 37.0000 - fp: 20.0000 - tn: 37.0000 - fn: 20.0000 - accuracy: 0.6491 - precision: 0.6491 - recall: 0.6491 - auc: 0.7781\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4074 - tp: 52.0000 - fp: 5.0000 - tn: 52.0000 - fn: 5.0000 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - auc: 0.9471\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2320 - tp: 54.0000 - fp: 3.0000 - tn: 54.0000 - fn: 3.0000 - accuracy: 0.9474 - precision: 0.9474 - recall: 0.9474 - auc: 0.9708 \n",
      "Predict: [1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1]\n",
      "True: [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "F1 score: 0.23999999999999996\n",
      "origin pos:20.0 neg:37.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.7007 - tp: 88.0000 - fp: 26.0000 - tn: 88.0000 - fn: 26.0000 - accuracy: 0.7719 - precision: 0.7719 - recall: 0.7719 - auc: 0.8623\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6882 - tp: 36.0000 - fp: 21.0000 - tn: 36.0000 - fn: 21.0000 - accuracy: 0.6316 - precision: 0.6316 - recall: 0.6316 - auc: 0.7005\n",
      "Epoch 3/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6486 - tp: 43.0000 - fp: 14.0000 - tn: 43.0000 - fn: 14.0000 - accuracy: 0.7544 - precision: 0.7544 - recall: 0.7544 - auc: 0.8510\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5264 - tp: 47.0000 - fp: 10.0000 - tn: 47.0000 - fn: 10.0000 - accuracy: 0.8246 - precision: 0.8246 - recall: 0.8246 - auc: 0.8707\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3003 - tp: 48.0000 - fp: 9.0000 - tn: 48.0000 - fn: 9.0000 - accuracy: 0.8421 - precision: 0.8421 - recall: 0.8421 - auc: 0.9461\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2404 - tp: 50.0000 - fp: 7.0000 - tn: 50.0000 - fn: 7.0000 - accuracy: 0.8772 - precision: 0.8772 - recall: 0.8772 - auc: 0.9769\n",
      "Predict: [1 1 1 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0 0 1 0]\n",
      "True: [0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0]\n",
      "F1 score: 0.3333333333333333\n",
      "Trustworthy\n",
      "origin pos:10.0 neg:46.0\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 1s 11ms/step - loss: 0.7007 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8761\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7650 - tp: 46.0000 - fp: 10.0000 - tn: 46.0000 - fn: 10.0000 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - auc: 0.7903\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6383 - tp: 46.0000 - fp: 10.0000 - tn: 46.0000 - fn: 10.0000 - accuracy: 0.8214 - precision: 0.8214 - recall: 0.8214 - auc: 0.9461\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5372 - tp: 48.0000 - fp: 8.0000 - tn: 48.0000 - fn: 8.0000 - accuracy: 0.8571 - precision: 0.8571 - recall: 0.8571 - auc: 0.9562\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3957 - tp: 52.0000 - fp: 4.0000 - tn: 52.0000 - fn: 4.0000 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - auc: 0.9829\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2937 - tp: 56.0000 - fp: 0.0000e+00 - tn: 56.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "F1 score: 0.0\n",
      "origin pos:18.0 neg:39.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 8ms/step - loss: 0.6992 - tp: 97.0000 - fp: 16.0000 - tn: 97.0000 - fn: 16.0000 - accuracy: 0.8584 - precision: 0.8584 - recall: 0.8584 - auc: 0.9121\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6916 - tp: 39.0000 - fp: 18.0000 - tn: 39.0000 - fn: 18.0000 - accuracy: 0.6842 - precision: 0.6842 - recall: 0.6842 - auc: 0.7581\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5940 - tp: 45.0000 - fp: 12.0000 - tn: 45.0000 - fn: 12.0000 - accuracy: 0.7895 - precision: 0.7895 - recall: 0.7895 - auc: 0.8914\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3832 - tp: 48.0000 - fp: 9.0000 - tn: 48.0000 - fn: 9.0000 - accuracy: 0.8421 - precision: 0.8421 - recall: 0.8421 - auc: 0.9609\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0788 - tp: 56.0000 - fp: 1.0000 - tn: 56.0000 - fn: 1.0000 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - auc: 0.9985 \n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1317 - tp: 54.0000 - fp: 3.0000 - tn: 54.0000 - fn: 3.0000 - accuracy: 0.9474 - precision: 0.9474 - recall: 0.9474 - auc: 0.9948 \n",
      "Predict: [0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "F1 score: 0.0\n",
      "origin pos:10.0 neg:47.0\n",
      "Epoch 1/6\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 0.7015 - tp: 78.0000 - fp: 36.0000 - tn: 78.0000 - fn: 36.0000 - accuracy: 0.6842 - precision: 0.6842 - recall: 0.6842 - auc: 0.8195\n",
      "Epoch 2/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6942 - tp: 47.0000 - fp: 10.0000 - tn: 47.0000 - fn: 10.0000 - accuracy: 0.8246 - precision: 0.8246 - recall: 0.8246 - auc: 0.8532\n",
      "Epoch 3/6\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6873 - tp: 47.0000 - fp: 10.0000 - tn: 47.0000 - fn: 10.0000 - accuracy: 0.8246 - precision: 0.8246 - recall: 0.8246 - auc: 0.8997\n",
      "Epoch 4/6\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6226 - tp: 47.0000 - fp: 10.0000 - tn: 47.0000 - fn: 10.0000 - accuracy: 0.8246 - precision: 0.8246 - recall: 0.8246 - auc: 0.9461\n",
      "Epoch 5/6\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4360 - tp: 47.0000 - fp: 10.0000 - tn: 47.0000 - fn: 10.0000 - accuracy: 0.8246 - precision: 0.8246 - recall: 0.8246 - auc: 0.9694\n",
      "Epoch 6/6\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3103 - tp: 57.0000 - fp: 0.0000e+00 - tn: 57.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000\n",
      "Predict: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1]\n",
      "F1 score: 0.19999999999999998\n"
     ]
    }
   ],
   "source": [
    "f1_dict = dict()\n",
    "for label in labels:\n",
    "    y_raw = df[label]\n",
    "    y = tf.keras.utils.to_categorical(y_raw)\n",
    "    \n",
    "    f1_dict[label] = []\n",
    "    print(label)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        neg = y_train.sum(axis=0)[0]\n",
    "        pos = y_train.sum(axis=0)[1]\n",
    "        total = pos + neg\n",
    "        print(f\"origin pos:{pos} neg:{neg}\")\n",
    "\n",
    "        # クラスの重み\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "        model = get_binary_model()\n",
    "        \n",
    "        # 初期重みの最適化\n",
    "        initial_bias = np.log([neg/pos])\n",
    "        model.layers[-1].bias_initializer=initial_bias\n",
    "        \n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=METRICS)\n",
    "        model.fit(X_train, y_train, batch_size=8, epochs=6, class_weight=class_weight)\n",
    "        y_pred = np.argmax(model.predict(X_test, batch_size=1), axis=1)\n",
    "        y_test_sk = np.argmax(y_test, axis=1)\n",
    "        print(\"Predict:\", y_pred)\n",
    "        print(\"True:\", y_test_sk)\n",
    "        f1 = f1_score(y_test_sk, y_pred, average=\"binary\")\n",
    "        print(\"F1 score:\", f1)\n",
    "        f1_dict[label].append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f44638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7699672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(\"Average F1 score per label\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45111c2",
   "metadata": {},
   "source": [
    "### いろいろやってみてわかること\n",
    " - Predictを見るとわかるが，まったく学習できていない\n",
    " - 役に立たない　やはりデータが少なすぎるか"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739a912",
   "metadata": {},
   "source": [
    "## おまけ？）LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e26a8ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01686239, -0.02080622, -0.10246906, ...,  0.01567093,\n",
       "         0.02755429, -0.00753543],\n",
       "       [ 0.02704587, -0.034787  ,  0.03670312, ...,  0.02411952,\n",
       "         0.00775679,  0.01972277],\n",
       "       [ 0.03997304, -0.01156947,  0.05490813, ...,  0.01107565,\n",
       "        -0.07515232,  0.02216491],\n",
       "       ...,\n",
       "       [ 0.00866971,  0.03657958, -0.02266627, ...,  0.08386027,\n",
       "        -0.00338471, -0.03355016],\n",
       "       [-0.01896611,  0.01163005, -0.01931574, ..., -0.07163159,\n",
       "        -0.10350168, -0.0057108 ],\n",
       "       [ 0.03666621, -0.03438604, -0.02219101, ..., -0.00174729,\n",
       "        -0.04289525,  0.00565334]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f59f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f862018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caring\n",
      "origin pos:21.0 neg:35.0\n",
      "Predict: [0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0]\n",
      "True: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "F1 score: 0.3\n",
      "origin pos:17.0 neg:40.0\n",
      "Predict: [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "True: [1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1]\n",
      "F1 score: 0.0\n",
      "origin pos:14.0 neg:43.0\n",
      "Predict: [0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True: [1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0]\n",
      "F1 score: 0.25\n",
      "Confident\n",
      "origin pos:43.0 neg:13.0\n",
      "Predict: [1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1]\n",
      "True: [1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1]\n",
      "F1 score: 0.8085106382978724\n",
      "origin pos:42.0 neg:15.0\n",
      "Predict: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1]\n",
      "True: [0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1]\n",
      "F1 score: 0.8571428571428572\n",
      "origin pos:45.0 neg:12.0\n",
      "Predict: [1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0]\n",
      "True: [1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1]\n",
      "F1 score: 0.7272727272727272\n",
      "Emotionally stable\n",
      "origin pos:16.0 neg:40.0\n",
      "Predict: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "True: [0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1]\n",
      "F1 score: 0.33333333333333337\n",
      "origin pos:23.0 neg:34.0\n",
      "Predict: [1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 1 0]\n",
      "True: [0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0]\n",
      "F1 score: 0.23529411764705885\n",
      "origin pos:19.0 neg:38.0\n",
      "Predict: [0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1]\n",
      "F1 score: 0.0\n",
      "Intelligent\n",
      "origin pos:35.0 neg:21.0\n",
      "Predict: [1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1]\n",
      "True: [0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1]\n",
      "F1 score: 0.42424242424242425\n",
      "origin pos:33.0 neg:24.0\n",
      "Predict: [0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 1 0 1 0]\n",
      "True: [0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1]\n",
      "F1 score: 0.47058823529411764\n",
      "origin pos:32.0 neg:25.0\n",
      "Predict: [1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1]\n",
      "True: [0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0 1 1]\n",
      "F1 score: 0.5806451612903226\n",
      "Responsible\n",
      "origin pos:25.0 neg:31.0\n",
      "Predict: [0 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0]\n",
      "True: [1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1]\n",
      "F1 score: 0.35714285714285715\n",
      "origin pos:28.0 neg:29.0\n",
      "Predict: [1 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1]\n",
      "True: [1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 0 1]\n",
      "F1 score: 0.6153846153846154\n",
      "origin pos:29.0 neg:28.0\n",
      "Predict: [1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0]\n",
      "True: [0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      "F1 score: 0.3636363636363636\n",
      "Sociable\n",
      "origin pos:16.0 neg:40.0\n",
      "Predict: [0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "True: [1 1 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0]\n",
      "F1 score: 0.10526315789473682\n",
      "origin pos:24.0 neg:33.0\n",
      "Predict: [1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 1]\n",
      "True: [0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0]\n",
      "F1 score: 0.3\n",
      "origin pos:20.0 neg:37.0\n",
      "Predict: [1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "True: [0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0]\n",
      "F1 score: 0.23529411764705882\n",
      "Trustworthy\n",
      "origin pos:10.0 neg:46.0\n",
      "Predict: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      "F1 score: 0.0\n",
      "origin pos:18.0 neg:39.0\n",
      "Predict: [0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "F1 score: 0.0\n",
      "origin pos:10.0 neg:47.0\n",
      "Predict: [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True: [0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1]\n",
      "F1 score: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "f1_dict = dict()\n",
    "for label in labels:\n",
    "    y_raw = df[label]\n",
    "    y = tf.keras.utils.to_categorical(y_raw)\n",
    "    \n",
    "    f1_dict[label] = []\n",
    "    print(label)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_test_sk = np.argmax(y_test, axis=1)\n",
    "        y_train_sk = np.argmax(y_train, axis=1)\n",
    "        \n",
    "        neg = y_train.sum(axis=0)[0]\n",
    "        pos = y_train.sum(axis=0)[1]\n",
    "        total = pos + neg\n",
    "        print(f\"origin pos:{pos} neg:{neg}\")\n",
    "\n",
    "        # クラスの重み\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "        model = lgb.LGBMClassifier(n_estimators=1000) \n",
    "        model.fit(X_train, y_train_sk) \n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(\"Predict:\", y_pred)\n",
    "        print(\"True:\", y_test_sk)\n",
    "        f1 = f1_score(y_test_sk, y_pred, average=\"binary\")\n",
    "        print(\"F1 score:\", f1)\n",
    "        f1_dict[label].append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd4b8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "993e276e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(\"Average F1 score per label\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5863fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
