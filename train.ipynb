{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06fea3d",
   "metadata": {},
   "source": [
    "# 学習と評価\n",
    " - FaceNetの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8fdcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51b929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d712f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c978fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d763348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8b5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83471da0",
   "metadata": {},
   "source": [
    "## データのロード\n",
    "\n",
    "- 画像サイズは224×224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c4d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36eab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Caring</th>\n",
       "      <th>Confident</th>\n",
       "      <th>Emotionally stable</th>\n",
       "      <th>Intelligent</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Sociable</th>\n",
       "      <th>Trustworthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>330524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>35629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>312270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>127529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>394899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>13583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Caring  Confident  Emotionally stable  Intelligent  Responsible  \\\n",
       "0    368079     0.0        0.0                 0.0          0.0          0.0   \n",
       "1    438384     1.0        1.0                 0.0          1.0          0.0   \n",
       "2     30155     1.0        1.0                 1.0          0.0          1.0   \n",
       "3    270812     0.0        0.0                 1.0          0.0          0.0   \n",
       "4    330524     0.0        1.0                 0.0          0.0          0.0   \n",
       "..      ...     ...        ...                 ...          ...          ...   \n",
       "250   35629     1.0        1.0                 0.0          0.0          0.0   \n",
       "251  312270     0.0        1.0                 0.0          0.0          0.0   \n",
       "252  127529     1.0        1.0                 1.0          0.0          0.0   \n",
       "253  394899     0.0        1.0                 0.0          0.0          0.0   \n",
       "254   13583     0.0        0.0                 0.0          0.0          1.0   \n",
       "\n",
       "     Sociable  Trustworthy  \n",
       "0         1.0          0.0  \n",
       "1         1.0          0.0  \n",
       "2         1.0          1.0  \n",
       "3         0.0          0.0  \n",
       "4         0.0          0.0  \n",
       "..        ...          ...  \n",
       "250       0.0          0.0  \n",
       "251       0.0          0.0  \n",
       "252       0.0          0.0  \n",
       "253       0.0          0.0  \n",
       "254       0.0          0.0  \n",
       "\n",
       "[255 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ecd64",
   "metadata": {},
   "source": [
    "## FaceNetで埋め込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48698ddb",
   "metadata": {},
   "source": [
    "メモ：```\\Lib\\site-packages\\facenet\\src\\facenet.py```の408行目をtensorflow v2仕様に書き換える必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bbf47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_embedding import FaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f8b7e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: ../facenet//20180402-114759/20180402-114759.pb\n",
      "WARNING:tensorflow:From C:\\Users\\Owner\\python_venvs\\tensorflow\\lib\\site-packages\\facenet\\src\\facenet.py:407: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "FACE_MEDEL_PATH = '../facenet//20180402-114759/20180402-114759.pb'\n",
    "face_embedding = FaceEmbedding(FACE_MEDEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6301e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for img_id in df[\"Id\"]:\n",
    "    path = f\"images/cleaned_20220519/{img_id}.jpg\"\n",
    "    face_vec = face_embedding.face_embeddings(path)[0]\n",
    "    X.append(face_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e77dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147fc0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 512)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546d6f1",
   "metadata": {},
   "source": [
    "# 二値分類モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4ca29",
   "metadata": {},
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d63c3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPool2D, Lambda, Conv2D, Reshape, Input, RandomFlip, RandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "016fb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_model():\n",
    "    input_ts = Input(shape=(512,))\n",
    "    dense1 = Dense(512, activation=\"relu\")(input_ts)\n",
    "    dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "    drop1 = Dropout(0.4, seed=SEED)(dense2)\n",
    "    dense3 = Dense(1024, activation=\"relu\")(drop1)\n",
    "    drop2 = Dropout(0.4, seed=SEED)(dense3)\n",
    "    dense4 = Dense(512, activation=\"relu\")(drop2)\n",
    "    dense5 = Dense(256, activation=\"relu\")(dense4)\n",
    "    dense6 = Dense(128, activation=\"relu\")(dense5)\n",
    "    drop3 = Dropout(0.2, seed=SEED)(dense6)\n",
    "    final = Dense(2, activation=\"softmax\")(drop3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_ts],\n",
    "        outputs=[final]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d25ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158b5902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,526,850\n",
      "Trainable params: 2,526,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565e1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c957700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bb8a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19ff1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4d914",
   "metadata": {},
   "source": [
    "cf. https://www.kaggle.com/code/rejpalcz/best-loss-function-for-f1-score-metric/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c9f2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8efe50",
   "metadata": {},
   "source": [
    "## すべてのラベルでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "449383e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Caring\",\"Confident\",\"Emotionally stable\",\"Intelligent\",\"Responsible\",\"Sociable\",\"Trustworthy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e9da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64b3039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3895cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b530f0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caring\n",
      "origin pos:18.0 neg:95.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 51ms/step - loss: 0.7389 - tp: 92.0000 - fp: 29.0000 - tn: 92.0000 - fn: 29.0000 - accuracy: 0.7603 - precision: 0.7603 - recall: 0.7603 - auc: 0.8115 - val_loss: 0.6368 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8359\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6846 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.8973 - val_loss: 0.5988 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8312\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5853 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9480 - val_loss: 0.6123 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.8203\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4419 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9513 - val_loss: 2.3647 - val_tp: 14.0000 - val_fp: 43.0000 - val_tn: 14.0000 - val_fn: 43.0000 - val_accuracy: 0.2456 - val_precision: 0.2456 - val_recall: 0.2456 - val_auc: 0.2478\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4329 - tp: 96.0000 - fp: 17.0000 - tn: 96.0000 - fn: 17.0000 - accuracy: 0.8496 - precision: 0.8496 - recall: 0.8496 - auc: 0.8812 - val_loss: 1.1639 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.8030\n",
      "Predict: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0]\n",
      "F1 score: 0.15384615384615383\n",
      "origin pos:19.0 neg:94.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.6896 - tp: 123.0000 - fp: 47.0000 - tn: 123.0000 - fn: 47.0000 - accuracy: 0.7235 - precision: 0.7235 - recall: 0.7235 - auc: 0.7636 - val_loss: 0.5960 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.7799\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6938 - tp: 92.0000 - fp: 21.0000 - tn: 92.0000 - fn: 21.0000 - accuracy: 0.8142 - precision: 0.8142 - recall: 0.8142 - auc: 0.8642 - val_loss: 0.6383 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.7722\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5347 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9168 - val_loss: 1.1154 - val_tp: 21.0000 - val_fp: 36.0000 - val_tn: 21.0000 - val_fn: 36.0000 - val_accuracy: 0.3684 - val_precision: 0.3684 - val_recall: 0.3684 - val_auc: 0.3866\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3286 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9319 - val_loss: 1.2091 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.7713\n",
      "Predict: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 1 1 1]\n",
      "True: [1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0]\n",
      "F1 score: 0.07142857142857142\n",
      "origin pos:18.0 neg:95.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 42ms/step - loss: 0.7130 - tp: 129.0000 - fp: 41.0000 - tn: 129.0000 - fn: 41.0000 - accuracy: 0.7588 - precision: 0.7588 - recall: 0.7588 - auc: 0.7557 - val_loss: 0.6563 - val_tp: 54.0000 - val_fp: 3.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.9474 - val_precision: 0.9474 - val_recall: 0.9474 - val_auc: 0.9800\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6752 - tp: 83.0000 - fp: 30.0000 - tn: 83.0000 - fn: 30.0000 - accuracy: 0.7345 - precision: 0.7345 - recall: 0.7345 - auc: 0.8422 - val_loss: 0.4443 - val_tp: 54.0000 - val_fp: 3.0000 - val_tn: 54.0000 - val_fn: 3.0000 - val_accuracy: 0.9474 - val_precision: 0.9474 - val_recall: 0.9474 - val_auc: 0.9794\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5380 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.9457 - val_loss: 0.5902 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.6922\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4367 - tp: 97.0000 - fp: 16.0000 - tn: 97.0000 - fn: 16.0000 - accuracy: 0.8584 - precision: 0.8584 - recall: 0.8584 - auc: 0.9490 - val_loss: 0.3491 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.9548\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.2453 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9352 - val_loss: 0.1770 - val_tp: 53.0000 - val_fp: 4.0000 - val_tn: 53.0000 - val_fn: 4.0000 - val_accuracy: 0.9298 - val_precision: 0.9298 - val_recall: 0.9298 - val_auc: 0.9581\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.2716 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9540 - val_loss: 0.6053 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7966\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.1143 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9766 - val_loss: 0.3013 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.9474\n",
      "Epoch 8/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2258 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9711 - val_loss: 0.2953 - val_tp: 52.0000 - val_fp: 5.0000 - val_tn: 52.0000 - val_fn: 5.0000 - val_accuracy: 0.9123 - val_precision: 0.9123 - val_recall: 0.9123 - val_auc: 0.9609\n",
      "Predict: [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 1 1]\n",
      "F1 score: 0.17647058823529413\n",
      "Confident\n",
      "origin pos:52.0 neg:61.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.7045 - tp: 103.0000 - fp: 67.0000 - tn: 103.0000 - fn: 67.0000 - accuracy: 0.6059 - precision: 0.6059 - recall: 0.6059 - auc: 0.7165 - val_loss: 0.6919 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5420\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6928 - tp: 60.0000 - fp: 53.0000 - tn: 60.0000 - fn: 53.0000 - accuracy: 0.5310 - precision: 0.5310 - recall: 0.5310 - auc: 0.5667 - val_loss: 0.6917 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5291\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6865 - tp: 61.0000 - fp: 52.0000 - tn: 61.0000 - fn: 52.0000 - accuracy: 0.5398 - precision: 0.5398 - recall: 0.5398 - auc: 0.5980 - val_loss: 0.6903 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.5432\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6391 - tp: 77.0000 - fp: 36.0000 - tn: 77.0000 - fn: 36.0000 - accuracy: 0.6814 - precision: 0.6814 - recall: 0.6814 - auc: 0.7364 - val_loss: 0.7023 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5208\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6112 - tp: 76.0000 - fp: 37.0000 - tn: 76.0000 - fn: 37.0000 - accuracy: 0.6726 - precision: 0.6726 - recall: 0.6726 - auc: 0.7059 - val_loss: 0.7418 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5768\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3727 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9072 - val_loss: 1.3073 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.5423\n",
      "Predict: [0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 1 0 0 0 1 0 1 0]\n",
      "True: [0 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 0 0 1 1 0 1 1 1 1 0]\n",
      "F1 score: 0.4878048780487805\n",
      "origin pos:59.0 neg:54.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.7024 - tp: 85.0000 - fp: 85.0000 - tn: 85.0000 - fn: 85.0000 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5000 - auc: 0.5075 - val_loss: 0.6910 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5436\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.7035 - tp: 56.0000 - fp: 57.0000 - tn: 56.0000 - fn: 57.0000 - accuracy: 0.4956 - precision: 0.4956 - recall: 0.4956 - auc: 0.4726 - val_loss: 0.6930 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5075\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6821 - tp: 62.0000 - fp: 51.0000 - tn: 62.0000 - fn: 51.0000 - accuracy: 0.5487 - precision: 0.5487 - recall: 0.5487 - auc: 0.6219 - val_loss: 0.6943 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5057\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6229 - tp: 72.0000 - fp: 41.0000 - tn: 72.0000 - fn: 41.0000 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - auc: 0.6946 - val_loss: 0.7062 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.5454\n",
      "Predict: [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 1]\n",
      "True: [1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 1 1 0]\n",
      "F1 score: 0.27586206896551724\n",
      "origin pos:57.0 neg:56.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.7014 - tp: 88.0000 - fp: 82.0000 - tn: 88.0000 - fn: 82.0000 - accuracy: 0.5176 - precision: 0.5176 - recall: 0.5176 - auc: 0.5162 - val_loss: 0.6941 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.4854\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6899 - tp: 51.0000 - fp: 62.0000 - tn: 51.0000 - fn: 62.0000 - accuracy: 0.4513 - precision: 0.4513 - recall: 0.4513 - auc: 0.5151 - val_loss: 0.6973 - val_tp: 29.0000 - val_fp: 28.0000 - val_tn: 29.0000 - val_fn: 28.0000 - val_accuracy: 0.5088 - val_precision: 0.5088 - val_recall: 0.5088 - val_auc: 0.5055\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6560 - tp: 65.0000 - fp: 48.0000 - tn: 65.0000 - fn: 48.0000 - accuracy: 0.5752 - precision: 0.5752 - recall: 0.5752 - auc: 0.6852 - val_loss: 0.7464 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4004\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5106 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.8271 - val_loss: 1.2423 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4211\n",
      "Predict: [1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1]\n",
      "True: [0 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 1 1\n",
      " 0 1 0 1 0 0 0 1 1 1 1]\n",
      "F1 score: 0.6078431372549019\n",
      "Emotionally stable\n",
      "origin pos:32.0 neg:81.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7415 - tp: 105.0000 - fp: 65.0000 - tn: 105.0000 - fn: 65.0000 - accuracy: 0.6176 - precision: 0.6176 - recall: 0.6176 - auc: 0.5546 - val_loss: 0.6848 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8224\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6941 - tp: 59.0000 - fp: 54.0000 - tn: 59.0000 - fn: 54.0000 - accuracy: 0.5221 - precision: 0.5221 - recall: 0.5221 - auc: 0.5305 - val_loss: 0.6878 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8095\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6832 - tp: 81.0000 - fp: 32.0000 - tn: 81.0000 - fn: 32.0000 - accuracy: 0.7168 - precision: 0.7168 - recall: 0.7168 - auc: 0.7851 - val_loss: 0.6189 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8215\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.6056 - tp: 81.0000 - fp: 32.0000 - tn: 81.0000 - fn: 32.0000 - accuracy: 0.7168 - precision: 0.7168 - recall: 0.7168 - auc: 0.8626 - val_loss: 0.5524 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.8086\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4760 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9399 - val_loss: 0.8283 - val_tp: 38.0000 - val_fp: 19.0000 - val_tn: 38.0000 - val_fn: 19.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7547\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2738 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9644 - val_loss: 1.4519 - val_tp: 42.0000 - val_fp: 15.0000 - val_tn: 42.0000 - val_fn: 15.0000 - val_accuracy: 0.7368 - val_precision: 0.7368 - val_recall: 0.7368 - val_auc: 0.7593\n",
      "Epoch 7/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3486 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9319 - val_loss: 1.6020 - val_tp: 35.0000 - val_fp: 22.0000 - val_tn: 35.0000 - val_fn: 22.0000 - val_accuracy: 0.6140 - val_precision: 0.6140 - val_recall: 0.6140 - val_auc: 0.5586\n",
      "Predict: [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1\n",
      " 0 0 0 1 1 0 0 1 1 0 1]\n",
      "True: [0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0]\n",
      "F1 score: 0.10256410256410256\n",
      "origin pos:27.0 neg:86.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.7083 - tp: 67.0000 - fp: 103.0000 - tn: 67.0000 - fn: 103.0000 - accuracy: 0.3941 - precision: 0.3941 - recall: 0.3941 - auc: 0.4392 - val_loss: 0.6372 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8529\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7189 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.7333 - val_loss: 0.6764 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8076\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6686 - tp: 87.0000 - fp: 26.0000 - tn: 87.0000 - fn: 26.0000 - accuracy: 0.7699 - precision: 0.7699 - recall: 0.7699 - auc: 0.8467 - val_loss: 0.5148 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8215\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6526 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8677 - val_loss: 0.6206 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.6970\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4663 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9428 - val_loss: 1.0030 - val_tp: 37.0000 - val_fp: 20.0000 - val_tn: 37.0000 - val_fn: 20.0000 - val_accuracy: 0.6491 - val_precision: 0.6491 - val_recall: 0.6491 - val_auc: 0.7196\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2715 - tp: 102.0000 - fp: 11.0000 - tn: 102.0000 - fn: 11.0000 - accuracy: 0.9027 - precision: 0.9027 - recall: 0.9027 - auc: 0.9519 - val_loss: 1.4072 - val_tp: 36.0000 - val_fp: 21.0000 - val_tn: 36.0000 - val_fn: 21.0000 - val_accuracy: 0.6316 - val_precision: 0.6316 - val_recall: 0.6316 - val_auc: 0.6716\n",
      "Predict: [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 1]\n",
      "True: [0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0]\n",
      "F1 score: 0.24390243902439024\n",
      "origin pos:22.0 neg:91.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7134 - tp: 119.0000 - fp: 51.0000 - tn: 119.0000 - fn: 51.0000 - accuracy: 0.7000 - precision: 0.7000 - recall: 0.7000 - auc: 0.6883 - val_loss: 0.6708 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8292\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6816 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8615 - val_loss: 0.5688 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8049\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.6247 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.9093 - val_loss: 0.6134 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.7759\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4198 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9801 - val_loss: 1.5563 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.7812\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3527 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9584 - val_loss: 2.4171 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5559\n",
      "Predict: [1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0\n",
      " 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0\n",
      " 0 0 0 0 1 1 1 0 1 0 0]\n",
      "True: [0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1]\n",
      "F1 score: 0.5151515151515151\n",
      "Intelligent\n",
      "origin pos:32.0 neg:81.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 45ms/step - loss: 0.6995 - tp: 93.0000 - fp: 77.0000 - tn: 93.0000 - fn: 77.0000 - accuracy: 0.5471 - precision: 0.5471 - recall: 0.5471 - auc: 0.5644 - val_loss: 0.6655 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.6273\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6893 - tp: 82.0000 - fp: 31.0000 - tn: 82.0000 - fn: 31.0000 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - auc: 0.7537 - val_loss: 0.7252 - val_tp: 16.0000 - val_fp: 41.0000 - val_tn: 16.0000 - val_fn: 41.0000 - val_accuracy: 0.2807 - val_precision: 0.2807 - val_recall: 0.2807 - val_auc: 0.1967\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6673 - tp: 60.0000 - fp: 53.0000 - tn: 60.0000 - fn: 53.0000 - accuracy: 0.5310 - precision: 0.5310 - recall: 0.5310 - auc: 0.5619 - val_loss: 0.7168 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6405\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6128 - tp: 82.0000 - fp: 31.0000 - tn: 82.0000 - fn: 31.0000 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - auc: 0.7794 - val_loss: 0.8715 - val_tp: 24.0000 - val_fp: 33.0000 - val_tn: 24.0000 - val_fn: 33.0000 - val_accuracy: 0.4211 - val_precision: 0.4211 - val_recall: 0.4211 - val_auc: 0.3730\n",
      "Predict: [1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 1 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1\n",
      " 1 0 0 1 1 0 1 1 1 1 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0]\n",
      "F1 score: 0.27692307692307694\n",
      "origin pos:31.0 neg:82.0\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 42ms/step - loss: 0.7172 - tp: 100.0000 - fp: 70.0000 - tn: 100.0000 - fn: 70.0000 - accuracy: 0.5882 - precision: 0.5882 - recall: 0.5882 - auc: 0.5469 - val_loss: 0.6832 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7415\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6941 - tp: 47.0000 - fp: 66.0000 - tn: 47.0000 - fn: 66.0000 - accuracy: 0.4159 - precision: 0.4159 - recall: 0.4159 - auc: 0.3884 - val_loss: 0.6878 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7236\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.6791 - tp: 83.0000 - fp: 30.0000 - tn: 83.0000 - fn: 30.0000 - accuracy: 0.7345 - precision: 0.7345 - recall: 0.7345 - auc: 0.7810 - val_loss: 0.6214 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7301\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5836 - tp: 86.0000 - fp: 27.0000 - tn: 86.0000 - fn: 27.0000 - accuracy: 0.7611 - precision: 0.7611 - recall: 0.7611 - auc: 0.8906 - val_loss: 0.7198 - val_tp: 28.0000 - val_fp: 29.0000 - val_tn: 28.0000 - val_fn: 29.0000 - val_accuracy: 0.4912 - val_precision: 0.4912 - val_recall: 0.4912 - val_auc: 0.5809\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3880 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9661 - val_loss: 1.4695 - val_tp: 26.0000 - val_fp: 31.0000 - val_tn: 26.0000 - val_fn: 31.0000 - val_accuracy: 0.4561 - val_precision: 0.4561 - val_recall: 0.4561 - val_auc: 0.4897\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2120 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9738 - val_loss: 2.8606 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.5155\n",
      "Predict: [0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 0 1 1 1 1 1 0]\n",
      "True: [1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1]\n",
      "F1 score: 0.3508771929824561\n",
      "origin pos:23.0 neg:90.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7079 - tp: 118.0000 - fp: 52.0000 - tn: 118.0000 - fn: 52.0000 - accuracy: 0.6941 - precision: 0.6941 - recall: 0.6941 - auc: 0.6296 - val_loss: 0.6708 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.7535\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6813 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.8610 - val_loss: 0.6011 - val_tp: 41.0000 - val_fp: 16.0000 - val_tn: 41.0000 - val_fn: 16.0000 - val_accuracy: 0.7193 - val_precision: 0.7193 - val_recall: 0.7193 - val_auc: 0.7516\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6208 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8956 - val_loss: 0.6007 - val_tp: 38.0000 - val_fp: 19.0000 - val_tn: 38.0000 - val_fn: 19.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7587\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.5305 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.9228 - val_loss: 0.6813 - val_tp: 35.0000 - val_fp: 22.0000 - val_tn: 35.0000 - val_fn: 22.0000 - val_accuracy: 0.6140 - val_precision: 0.6140 - val_recall: 0.6140 - val_auc: 0.7053\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2645 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9743 - val_loss: 1.4820 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.6787\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.2552 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9704 - val_loss: 1.0483 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6774\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 1 1 1 0 1 0 0 0]\n",
      "F1 score: 0.16666666666666666\n",
      "Responsible\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 0.6933 - tp: 108.0000 - fp: 62.0000 - tn: 108.0000 - fn: 62.0000 - accuracy: 0.6353 - precision: 0.6353 - recall: 0.6353 - auc: 0.7018 - val_loss: 0.5010 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8495\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.7172 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9113 - val_loss: 0.6302 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8463\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6463 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9447 - val_loss: 0.5077 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.8418\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3728 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9892 - val_loss: 1.0470 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8615\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 1]\n",
      "F1 score: 0.2\n",
      "origin pos:20.0 neg:93.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.7139 - tp: 132.0000 - fp: 38.0000 - tn: 132.0000 - fn: 38.0000 - accuracy: 0.7765 - precision: 0.7765 - recall: 0.7765 - auc: 0.7954 - val_loss: 0.6566 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7110\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6846 - tp: 93.0000 - fp: 20.0000 - tn: 93.0000 - fn: 20.0000 - accuracy: 0.8230 - precision: 0.8230 - recall: 0.8230 - auc: 0.8663 - val_loss: 0.6214 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7258\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 13ms/step - loss: 0.5832 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9342 - val_loss: 0.6847 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.6805\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4777 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9507 - val_loss: 1.3256 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7618\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2325 - tp: 104.0000 - fp: 9.0000 - tn: 104.0000 - fn: 9.0000 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - auc: 0.9512 - val_loss: 2.7820 - val_tp: 43.0000 - val_fp: 14.0000 - val_tn: 43.0000 - val_fn: 14.0000 - val_accuracy: 0.7544 - val_precision: 0.7544 - val_recall: 0.7544 - val_auc: 0.7765\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.0\n",
      "origin pos:22.0 neg:91.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 49ms/step - loss: 0.8042 - tp: 127.0000 - fp: 43.0000 - tn: 127.0000 - fn: 43.0000 - accuracy: 0.7471 - precision: 0.7471 - recall: 0.7471 - auc: 0.7614 - val_loss: 0.6788 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8483\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6884 - tp: 90.0000 - fp: 23.0000 - tn: 90.0000 - fn: 23.0000 - accuracy: 0.7965 - precision: 0.7965 - recall: 0.7965 - auc: 0.8846 - val_loss: 0.6615 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8289\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6654 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8735 - val_loss: 0.5477 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8236\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5537 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9462 - val_loss: 0.6849 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8086\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4409 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9801 - val_loss: 1.0187 - val_tp: 31.0000 - val_fp: 26.0000 - val_tn: 31.0000 - val_fn: 26.0000 - val_accuracy: 0.5439 - val_precision: 0.5439 - val_recall: 0.5439 - val_auc: 0.6580\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3198 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9623 - val_loss: 1.3861 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7861\n",
      "Predict: [0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0]\n",
      "True: [0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 1 0 1 0 1 0 0 0]\n",
      "F1 score: 0.0625\n",
      "Sociable\n",
      "origin pos:10.0 neg:103.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 44ms/step - loss: 0.7864 - tp: 143.0000 - fp: 27.0000 - tn: 143.0000 - fn: 27.0000 - accuracy: 0.8412 - precision: 0.8412 - recall: 0.8412 - auc: 0.8337 - val_loss: 0.5670 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7679\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.7245 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9367 - val_loss: 0.6252 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7787\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6421 - tp: 105.0000 - fp: 8.0000 - tn: 105.0000 - fn: 8.0000 - accuracy: 0.9292 - precision: 0.9292 - recall: 0.9292 - auc: 0.9575 - val_loss: 0.6919 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.7833\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.4227 - tp: 109.0000 - fp: 4.0000 - tn: 109.0000 - fn: 4.0000 - accuracy: 0.9646 - precision: 0.9646 - recall: 0.9646 - auc: 0.9953 - val_loss: 1.1280 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.8070\n",
      "Predict: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "True: [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.10526315789473685\n",
      "origin pos:21.0 neg:92.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 47ms/step - loss: 0.7670 - tp: 133.0000 - fp: 37.0000 - tn: 133.0000 - fn: 37.0000 - accuracy: 0.7824 - precision: 0.7824 - recall: 0.7824 - auc: 0.7882 - val_loss: 0.6282 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8775\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6852 - tp: 91.0000 - fp: 22.0000 - tn: 91.0000 - fn: 22.0000 - accuracy: 0.8053 - precision: 0.8053 - recall: 0.8053 - auc: 0.8640 - val_loss: 0.6588 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8797\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6192 - tp: 94.0000 - fp: 19.0000 - tn: 94.0000 - fn: 19.0000 - accuracy: 0.8319 - precision: 0.8319 - recall: 0.8319 - auc: 0.9265 - val_loss: 0.4225 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8680\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.5825 - tp: 95.0000 - fp: 18.0000 - tn: 95.0000 - fn: 18.0000 - accuracy: 0.8407 - precision: 0.8407 - recall: 0.8407 - auc: 0.9195 - val_loss: 0.6381 - val_tp: 30.0000 - val_fp: 27.0000 - val_tn: 30.0000 - val_fn: 27.0000 - val_accuracy: 0.5263 - val_precision: 0.5263 - val_recall: 0.5263 - val_auc: 0.6196\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4598 - tp: 96.0000 - fp: 17.0000 - tn: 96.0000 - fn: 17.0000 - accuracy: 0.8496 - precision: 0.8496 - recall: 0.8496 - auc: 0.9056 - val_loss: 0.7612 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8806\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 10ms/step - loss: 0.3254 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9706 - val_loss: 0.8565 - val_tp: 33.0000 - val_fp: 24.0000 - val_tn: 33.0000 - val_fn: 24.0000 - val_accuracy: 0.5789 - val_precision: 0.5789 - val_recall: 0.5789 - val_auc: 0.6033\n",
      "Predict: [0 1 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 1]\n",
      "True: [1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0]\n",
      "F1 score: 0.2\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 46ms/step - loss: 0.7427 - tp: 130.0000 - fp: 40.0000 - tn: 130.0000 - fn: 40.0000 - accuracy: 0.7647 - precision: 0.7647 - recall: 0.7647 - auc: 0.7116 - val_loss: 0.6384 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8947\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.6721 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9148 - val_loss: 0.4967 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.9040\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5581 - tp: 99.0000 - fp: 14.0000 - tn: 99.0000 - fn: 14.0000 - accuracy: 0.8761 - precision: 0.8761 - recall: 0.8761 - auc: 0.9680 - val_loss: 0.4772 - val_tp: 40.0000 - val_fp: 17.0000 - val_tn: 40.0000 - val_fn: 17.0000 - val_accuracy: 0.7018 - val_precision: 0.7018 - val_recall: 0.7018 - val_auc: 0.8680\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.4232 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9911 - val_loss: 0.6599 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8495\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1965 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9857 - val_loss: 1.4244 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.6531\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3275 - tp: 105.0000 - fp: 8.0000 - tn: 105.0000 - fn: 8.0000 - accuracy: 0.9292 - precision: 0.9292 - recall: 0.9292 - auc: 0.9593 - val_loss: 0.7944 - val_tp: 39.0000 - val_fp: 18.0000 - val_tn: 39.0000 - val_fn: 18.0000 - val_accuracy: 0.6842 - val_precision: 0.6842 - val_recall: 0.6842 - val_auc: 0.7288\n",
      "Predict: [1 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 0 0 0]\n",
      "F1 score: 0.2564102564102564\n",
      "Trustworthy\n",
      "origin pos:10.0 neg:103.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 43ms/step - loss: 1.1078 - tp: 140.0000 - fp: 30.0000 - tn: 140.0000 - fn: 30.0000 - accuracy: 0.8235 - precision: 0.8235 - recall: 0.8235 - auc: 0.8208 - val_loss: 0.5818 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.9018\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.6708 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9612 - val_loss: 0.5656 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8981\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5929 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9668 - val_loss: 0.4309 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8846\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4313 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9954 - val_loss: 0.8369 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8578\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4392 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9930 - val_loss: 0.6186 - val_tp: 46.0000 - val_fp: 11.0000 - val_tn: 46.0000 - val_fn: 11.0000 - val_accuracy: 0.8070 - val_precision: 0.8070 - val_recall: 0.8070 - val_auc: 0.8640\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.4507 - tp: 111.0000 - fp: 2.0000 - tn: 111.0000 - fn: 2.0000 - accuracy: 0.9823 - precision: 0.9823 - recall: 0.9823 - auc: 0.9886 - val_loss: 0.5981 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.8596\n",
      "Predict: [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0]\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0]\n",
      "F1 score: 0.1\n",
      "origin pos:15.0 neg:98.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 47ms/step - loss: 0.7057 - tp: 141.0000 - fp: 29.0000 - tn: 141.0000 - fn: 29.0000 - accuracy: 0.8294 - precision: 0.8294 - recall: 0.8294 - auc: 0.8228 - val_loss: 0.5690 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8633\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.6829 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9286 - val_loss: 0.5439 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8732\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5146 - tp: 101.0000 - fp: 12.0000 - tn: 101.0000 - fn: 12.0000 - accuracy: 0.8938 - precision: 0.8938 - recall: 0.8938 - auc: 0.9678 - val_loss: 0.6069 - val_tp: 47.0000 - val_fp: 10.0000 - val_tn: 47.0000 - val_fn: 10.0000 - val_accuracy: 0.8246 - val_precision: 0.8246 - val_recall: 0.8246 - val_auc: 0.8541\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.3545 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9908 - val_loss: 1.5737 - val_tp: 49.0000 - val_fp: 8.0000 - val_tn: 49.0000 - val_fn: 8.0000 - val_accuracy: 0.8596 - val_precision: 0.8596 - val_recall: 0.8596 - val_auc: 0.8473\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.1719 - tp: 108.0000 - fp: 5.0000 - tn: 108.0000 - fn: 5.0000 - accuracy: 0.9558 - precision: 0.9558 - recall: 0.9558 - auc: 0.9597 - val_loss: 2.1212 - val_tp: 44.0000 - val_fp: 13.0000 - val_tn: 44.0000 - val_fn: 13.0000 - val_accuracy: 0.7719 - val_precision: 0.7719 - val_recall: 0.7719 - val_auc: 0.7870\n",
      "Predict: [0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1]\n",
      "True: [0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0]\n",
      "F1 score: 0.14814814814814814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin pos:13.0 neg:100.0\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 2s 48ms/step - loss: 0.9025 - tp: 136.0000 - fp: 34.0000 - tn: 136.0000 - fn: 34.0000 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - auc: 0.8136 - val_loss: 0.6425 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8917\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6826 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9410 - val_loss: 0.6362 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.9012\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6064 - tp: 100.0000 - fp: 13.0000 - tn: 100.0000 - fn: 13.0000 - accuracy: 0.8850 - precision: 0.8850 - recall: 0.8850 - auc: 0.9586 - val_loss: 0.4003 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8987\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.5087 - tp: 98.0000 - fp: 15.0000 - tn: 98.0000 - fn: 15.0000 - accuracy: 0.8673 - precision: 0.8673 - recall: 0.8673 - auc: 0.9751 - val_loss: 0.4607 - val_tp: 45.0000 - val_fp: 12.0000 - val_tn: 45.0000 - val_fn: 12.0000 - val_accuracy: 0.7895 - val_precision: 0.7895 - val_recall: 0.7895 - val_auc: 0.8997\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.4551 - tp: 103.0000 - fp: 10.0000 - tn: 103.0000 - fn: 10.0000 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - auc: 0.9811 - val_loss: 0.5677 - val_tp: 50.0000 - val_fp: 7.0000 - val_tn: 50.0000 - val_fn: 7.0000 - val_accuracy: 0.8772 - val_precision: 0.8772 - val_recall: 0.8772 - val_auc: 0.8852\n",
      "Epoch 6/15\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.3919 - tp: 107.0000 - fp: 6.0000 - tn: 107.0000 - fn: 6.0000 - accuracy: 0.9469 - precision: 0.9469 - recall: 0.9469 - auc: 0.9898 - val_loss: 0.5337 - val_tp: 48.0000 - val_fp: 9.0000 - val_tn: 48.0000 - val_fn: 9.0000 - val_accuracy: 0.8421 - val_precision: 0.8421 - val_recall: 0.8421 - val_auc: 0.8809\n",
      "Predict: [1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0]\n",
      "F1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "f1_dict = dict()\n",
    "y_true_preds = dict()\n",
    "\n",
    "for label in labels:\n",
    "    y_raw = df[label]\n",
    "    y = tf.keras.utils.to_categorical(y_raw)\n",
    "    \n",
    "    f1_dict[label] = []\n",
    "    y_true_preds[label] = []\n",
    "    print(label)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):     \n",
    "        X_val_train, X_test = X[train_index], X[test_index]\n",
    "        y_val_train, y_test = y[train_index], y[test_index]\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_val_train, y_val_train, test_size=0.333, random_state=SEED)\n",
    "        \n",
    "        neg = y_train.sum(axis=0)[0]\n",
    "        pos = y_train.sum(axis=0)[1]\n",
    "        total = pos + neg\n",
    "        print(f\"origin pos:{pos} neg:{neg}\")\n",
    "\n",
    "        # クラスの重み\n",
    "        weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "        weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "        class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "        \n",
    "        model = get_binary_model()\n",
    "        \n",
    "        # 初期重みの最適化\n",
    "        initial_bias = np.log([neg/pos])\n",
    "        model.layers[-1].bias_initializer=initial_bias\n",
    "        \n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=METRICS)\n",
    "        es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='auto')\n",
    "        model.fit(X_train, y_train, batch_size=8, epochs=15, class_weight=class_weight, callbacks=[es_cb], validation_data=[X_val, y_val])\n",
    "        y_pred_tf = model.predict(X_test, batch_size=1)\n",
    "        y_pred = np.argmax(y_pred_tf, axis=1)\n",
    "        y_test_sk = np.argmax(y_test, axis=1)\n",
    "        print(\"Predict:\", y_pred)\n",
    "        print(\"True:\", y_test_sk)\n",
    "        f1 = f1_score(y_test_sk, y_pred, average=\"binary\")\n",
    "        print(\"F1 score:\", f1)\n",
    "        f1_dict[label].append(f1)\n",
    "        y_true_preds[label].append((y_test_sk, y_pred))\n",
    "        del model\n",
    "        gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51125f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2431372549019608"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HL = 0\n",
    "cnt = 0\n",
    "for l in labels:\n",
    "    for k in range(3):\n",
    "        y_true, y_pred = y_true_preds[label][k]\n",
    "        HL += hamming_loss(y_true, y_pred)\n",
    "        cnt += 1\n",
    "HL /= cnt\n",
    "HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f44638be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))\n",
    "macro_f1_val = np.mean(f1_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7699672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(f\"F1 score per label  (macro-f1: {macro_f1_val:.3f}, , Hamming Loss: {HL:.3f}, k=4)\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45111c2",
   "metadata": {},
   "source": [
    "### いろいろやってみてわかること\n",
    " - Predictを見るとわかるが，まったく学習できていない\n",
    " - 役に立たない　やはりデータが少なすぎるか\n",
    " - f1をlossに用いるほうが全然良い\n",
    " - macro-f1はf1の平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bf039",
   "metadata": {},
   "source": [
    "# マルチラベル問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97351565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_model():\n",
    "    input_ts = Input(shape=(512,))\n",
    "    dense1 = Dense(512, activation=\"relu\")(input_ts)\n",
    "    dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "    drop1 = Dropout(0.4, seed=SEED)(dense2)\n",
    "    dense3 = Dense(1024, activation=\"relu\")(drop1)\n",
    "    drop2 = Dropout(0.4, seed=SEED)(dense3)\n",
    "    dense4 = Dense(512, activation=\"relu\")(drop2)\n",
    "    dense5 = Dense(256, activation=\"relu\")(dense4)\n",
    "    dense6 = Dense(128, activation=\"relu\")(dense5)\n",
    "    drop3 = Dropout(0.2, seed=SEED)(dense6)\n",
    "    final = Dense(len(labels), activation=\"sigmoid\")(drop3)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs=[input_ts],\n",
    "        outputs=[final]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e44ab02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_multi_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f915e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_79 (InputLayer)       [(None, 512)]             0         \n",
      "                                                                 \n",
      " dense_546 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_547 (Dense)           (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout_234 (Dropout)       (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_548 (Dense)           (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_235 (Dropout)       (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_549 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_550 (Dense)           (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_551 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_236 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_552 (Dense)           (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,527,495\n",
      "Trainable params: 2,527,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "38a8ea24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Confident\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fb5ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df.T[1:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1ddc464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 1., 0., 1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9131ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39., 126.,  57.,  66.,  45.,  36.,  31.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=0) # 各ラベルの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "87fcabdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1fc6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = y.sum(axis=0) / len(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05146db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15294118, 0.49411765, 0.22352941, 0.25882353, 0.17647059,\n",
       "       0.14117647, 0.12156863])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c7dec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 0.5873 - acc: 0.2389 - val_loss: 0.5427 - val_acc: 0.3333\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4898 - acc: 0.3363 - val_loss: 0.5554 - val_acc: 0.3333\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4761 - acc: 0.1858 - val_loss: 0.5965 - val_acc: 0.3333\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4514 - acc: 0.3363 - val_loss: 0.5702 - val_acc: 0.3333\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5520 - acc: 0.4941\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.6062 - acc: 0.3363 - val_loss: 0.5486 - val_acc: 0.4386\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5320 - acc: 0.4248 - val_loss: 0.5412 - val_acc: 0.4386\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4833 - acc: 0.4159 - val_loss: 0.5899 - val_acc: 0.4386\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4506 - acc: 0.4248 - val_loss: 0.5872 - val_acc: 0.4386\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4316 - acc: 0.4248 - val_loss: 0.6037 - val_acc: 0.4386\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5257 - acc: 0.3882\n",
      "Epoch 1/15\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.5613 - acc: 0.3894 - val_loss: 0.4975 - val_acc: 0.4561\n",
      "Epoch 2/15\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.5010 - acc: 0.3717 - val_loss: 0.4716 - val_acc: 0.4561\n",
      "Epoch 3/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4738 - acc: 0.4336 - val_loss: 0.4773 - val_acc: 0.4561\n",
      "Epoch 4/15\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4469 - acc: 0.4336 - val_loss: 0.4821 - val_acc: 0.4561\n",
      "Epoch 5/15\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4286 - acc: 0.4336 - val_loss: 0.4870 - val_acc: 0.4561\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5735 - acc: 0.3647\n"
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "for train_index, test_index in kf.split(X):     \n",
    "    X_val_train, X_test = X[train_index], X[test_index]\n",
    "    y_val_train, y_test = y[train_index], y[test_index]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_val_train, y_val_train, test_size=0.333, random_state=SEED)\n",
    "\n",
    "    model = get_multi_model()\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='auto')\n",
    "    model.fit(X_train, y_train, batch_size=8, epochs=15,  callbacks=[es_cb], validation_data=[X_val, y_val])\n",
    "    model.evaluate(X_test,y_test)\n",
    "    y_pred = model.predict(X_test, batch_size=1)\n",
    "    y_preds.append(y_pred)\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e62ac759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.3504647 , 0.5133178 , 0.41513702, 0.40172338, 0.29465353,\n",
       "         0.23827103, 0.2787822 ],\n",
       "        [0.10067739, 0.5618096 , 0.24797939, 0.22042526, 0.04356267,\n",
       "         0.01720896, 0.03515984],\n",
       "        [0.12873566, 0.5511476 , 0.2649153 , 0.23839432, 0.06084595,\n",
       "         0.02660974, 0.05106943],\n",
       "        [0.17041212, 0.55062926, 0.31030235, 0.28979138, 0.09891968,\n",
       "         0.05334357, 0.08713944],\n",
       "        [0.14301263, 0.5656834 , 0.29003695, 0.2604343 , 0.07446929,\n",
       "         0.03587171, 0.06562696],\n",
       "        [0.31857163, 0.51682836, 0.39822397, 0.38329327, 0.25350705,\n",
       "         0.19303676, 0.23723665],\n",
       "        [0.04740989, 0.5989822 , 0.18341741, 0.1502343 , 0.01428592,\n",
       "         0.00399168, 0.01117025],\n",
       "        [0.20134366, 0.53491944, 0.32051727, 0.3043929 , 0.12299959,\n",
       "         0.07048188, 0.10877611],\n",
       "        [0.33054096, 0.51560605, 0.40657553, 0.39149052, 0.26918688,\n",
       "         0.21036232, 0.25219193],\n",
       "        [0.22988212, 0.5355606 , 0.34646422, 0.32603836, 0.15353568,\n",
       "         0.09535833, 0.139192  ],\n",
       "        [0.10068997, 0.56001705, 0.24742693, 0.22444707, 0.04379583,\n",
       "         0.01741073, 0.0352388 ],\n",
       "        [0.08648286, 0.5740479 , 0.23333514, 0.20433314, 0.03487217,\n",
       "         0.01292179, 0.02849411],\n",
       "        [0.13228263, 0.55588114, 0.27632278, 0.2524431 , 0.06702604,\n",
       "         0.03077553, 0.05640097],\n",
       "        [0.22645393, 0.5419163 , 0.35245022, 0.32591948, 0.15207082,\n",
       "         0.09444369, 0.139126  ],\n",
       "        [0.16172199, 0.54378355, 0.29445943, 0.2759883 , 0.08743904,\n",
       "         0.04480311, 0.07575505],\n",
       "        [0.13853778, 0.5626301 , 0.2971935 , 0.25938183, 0.07211939,\n",
       "         0.03431135, 0.06243604],\n",
       "        [0.19549285, 0.54062337, 0.324282  , 0.3074621 , 0.1221423 ,\n",
       "         0.0694377 , 0.10731456],\n",
       "        [0.30830526, 0.5187534 , 0.39208704, 0.37794238, 0.24226145,\n",
       "         0.1812647 , 0.22574703],\n",
       "        [0.07993279, 0.58121705, 0.22447959, 0.19631585, 0.03172226,\n",
       "         0.01126304, 0.02560228],\n",
       "        [0.22876981, 0.533422  , 0.34473312, 0.32608962, 0.15230522,\n",
       "         0.09511626, 0.13677745],\n",
       "        [0.28168494, 0.52292955, 0.37624195, 0.36043078, 0.20973559,\n",
       "         0.14818192, 0.19365229],\n",
       "        [0.13125134, 0.55223864, 0.27211088, 0.24857463, 0.06424203,\n",
       "         0.02904901, 0.05363234],\n",
       "        [0.06917281, 0.5781363 , 0.2108595 , 0.18578495, 0.02556571,\n",
       "         0.00854009, 0.02010802],\n",
       "        [0.35674363, 0.5148842 , 0.42343462, 0.40924382, 0.30452543,\n",
       "         0.2504097 , 0.29115102],\n",
       "        [0.16273521, 0.5422862 , 0.29057857, 0.27437204, 0.08898579,\n",
       "         0.04505267, 0.07652714],\n",
       "        [0.24783078, 0.52796304, 0.35094613, 0.3328713 , 0.16927135,\n",
       "         0.10954706, 0.15321335],\n",
       "        [0.31467348, 0.518276  , 0.3937424 , 0.37918335, 0.24836902,\n",
       "         0.18763766, 0.23307684],\n",
       "        [0.224453  , 0.53572404, 0.34716842, 0.32421023, 0.14877544,\n",
       "         0.09228404, 0.13437486],\n",
       "        [0.17123783, 0.55328   , 0.31690726, 0.28453243, 0.09895822,\n",
       "         0.05283958, 0.08854198],\n",
       "        [0.07518187, 0.56986636, 0.2197122 , 0.18987918, 0.02870128,\n",
       "         0.00970442, 0.02177599],\n",
       "        [0.08203606, 0.5741413 , 0.2270748 , 0.19525719, 0.03184804,\n",
       "         0.01111537, 0.02531035],\n",
       "        [0.20786606, 0.53957546, 0.33526668, 0.31840715, 0.13357736,\n",
       "         0.07965124, 0.11845449],\n",
       "        [0.27637845, 0.52717084, 0.37606514, 0.35613889, 0.20198058,\n",
       "         0.14145331, 0.18751106],\n",
       "        [0.17471543, 0.5433051 , 0.30637145, 0.28237212, 0.10055917,\n",
       "         0.05320193, 0.0868196 ],\n",
       "        [0.22654349, 0.5261296 , 0.3352212 , 0.31970456, 0.146901  ,\n",
       "         0.08990255, 0.13046679],\n",
       "        [0.16172452, 0.54614514, 0.2997046 , 0.27125886, 0.0889696 ,\n",
       "         0.04482518, 0.07561036],\n",
       "        [0.21399772, 0.5377171 , 0.34077337, 0.3223965 , 0.14045265,\n",
       "         0.08452684, 0.12465233],\n",
       "        [0.09490015, 0.5717724 , 0.24294509, 0.21884601, 0.04085147,\n",
       "         0.01592814, 0.03365317],\n",
       "        [0.17156224, 0.55255526, 0.30823874, 0.28267118, 0.09726939,\n",
       "         0.05113007, 0.08660507],\n",
       "        [0.16987516, 0.5452987 , 0.30428168, 0.28622204, 0.09695089,\n",
       "         0.05157786, 0.08462079],\n",
       "        [0.16712359, 0.546749  , 0.3070704 , 0.2804637 , 0.09204685,\n",
       "         0.04756727, 0.08014942],\n",
       "        [0.08949659, 0.5667135 , 0.23175383, 0.20674114, 0.03706435,\n",
       "         0.01384067, 0.02982031],\n",
       "        [0.1758188 , 0.5423633 , 0.31000212, 0.2873021 , 0.10080147,\n",
       "         0.0532413 , 0.08696955],\n",
       "        [0.06652526, 0.5885297 , 0.20948431, 0.17947863, 0.02399234,\n",
       "         0.00767833, 0.01944874],\n",
       "        [0.12980734, 0.5558719 , 0.27905223, 0.25523603, 0.06515512,\n",
       "         0.02975075, 0.05487659],\n",
       "        [0.27493116, 0.5276771 , 0.37436542, 0.35392103, 0.2032351 ,\n",
       "         0.14136033, 0.18895356],\n",
       "        [0.24540251, 0.5302571 , 0.36066636, 0.33909222, 0.170224  ,\n",
       "         0.11037552, 0.15491499],\n",
       "        [0.05749388, 0.57807875, 0.19337213, 0.16694556, 0.01920222,\n",
       "         0.00579252, 0.01426855],\n",
       "        [0.17993471, 0.5504307 , 0.31528386, 0.288503  , 0.10662222,\n",
       "         0.05775968, 0.09542374],\n",
       "        [0.15936759, 0.5447621 , 0.29707476, 0.27685943, 0.08759509,\n",
       "         0.04426647, 0.07500026],\n",
       "        [0.1500112 , 0.5611343 , 0.29311147, 0.26196945, 0.07867225,\n",
       "         0.03834414, 0.07007942],\n",
       "        [0.13334394, 0.56148106, 0.28709573, 0.25591344, 0.06739308,\n",
       "         0.031475  , 0.05828296],\n",
       "        [0.10039383, 0.57182527, 0.2478821 , 0.2145406 , 0.04439202,\n",
       "         0.01731247, 0.0358458 ],\n",
       "        [0.27253008, 0.5289748 , 0.3756966 , 0.35800126, 0.20181592,\n",
       "         0.14082827, 0.18613367],\n",
       "        [0.16529426, 0.5496083 , 0.30019373, 0.27952385, 0.09251408,\n",
       "         0.04790127, 0.08121331],\n",
       "        [0.26575434, 0.5329403 , 0.37336466, 0.35275397, 0.19136047,\n",
       "         0.13192734, 0.17805263],\n",
       "        [0.15085302, 0.5322134 , 0.27192098, 0.25774834, 0.07721376,\n",
       "         0.03684805, 0.06354132],\n",
       "        [0.28143162, 0.5230881 , 0.374284  , 0.3576288 , 0.20811026,\n",
       "         0.14639449, 0.19166286],\n",
       "        [0.12331189, 0.5663302 , 0.27595344, 0.24788351, 0.06048594,\n",
       "         0.02708605, 0.05167579],\n",
       "        [0.2900399 , 0.52096033, 0.38393316, 0.36879036, 0.22203606,\n",
       "         0.16012226, 0.20434844],\n",
       "        [0.2795491 , 0.5250584 , 0.3788683 , 0.36413935, 0.20961337,\n",
       "         0.14867762, 0.19355454],\n",
       "        [0.12949595, 0.55063885, 0.2668462 , 0.24278496, 0.06188404,\n",
       "         0.02760467, 0.05162168],\n",
       "        [0.26556987, 0.5276664 , 0.36646295, 0.3507371 , 0.19240774,\n",
       "         0.13136145, 0.17708187],\n",
       "        [0.23742975, 0.5333833 , 0.35891274, 0.33581704, 0.16262989,\n",
       "         0.10450072, 0.14800778],\n",
       "        [0.14590861, 0.5525488 , 0.28764486, 0.2646941 , 0.07676774,\n",
       "         0.03757324, 0.06603394],\n",
       "        [0.08266046, 0.571982  , 0.22468449, 0.20004037, 0.03171761,\n",
       "         0.01137857, 0.02567984],\n",
       "        [0.08454129, 0.58289176, 0.23702699, 0.20495059, 0.03414545,\n",
       "         0.01270193, 0.02876796],\n",
       "        [0.18246095, 0.5448306 , 0.31711242, 0.29037696, 0.10807227,\n",
       "         0.0590937 , 0.09560283],\n",
       "        [0.29744768, 0.52134734, 0.39099067, 0.37115684, 0.22921051,\n",
       "         0.16718012, 0.21349418],\n",
       "        [0.12438612, 0.55704   , 0.27706963, 0.2432359 , 0.05951907,\n",
       "         0.02628111, 0.04969598],\n",
       "        [0.17282566, 0.53713095, 0.30375576, 0.28240764, 0.09738586,\n",
       "         0.05081326, 0.08329151],\n",
       "        [0.26982296, 0.53086334, 0.3772315 , 0.35719723, 0.19903414,\n",
       "         0.13823998, 0.18552136],\n",
       "        [0.20763183, 0.53774416, 0.32929978, 0.30792725, 0.12863925,\n",
       "         0.0756177 , 0.11521073],\n",
       "        [0.15764365, 0.5533683 , 0.30427256, 0.2747079 , 0.08634025,\n",
       "         0.04364518, 0.07529519],\n",
       "        [0.05927482, 0.5948058 , 0.20204504, 0.17186283, 0.0207158 ,\n",
       "         0.00645752, 0.01683617],\n",
       "        [0.14924103, 0.55044276, 0.29421055, 0.26391438, 0.0803799 ,\n",
       "         0.03866937, 0.06764298],\n",
       "        [0.24819368, 0.5278126 , 0.35545447, 0.3341114 , 0.17182772,\n",
       "         0.11103662, 0.1566064 ],\n",
       "        [0.2432237 , 0.5288696 , 0.3529721 , 0.3383586 , 0.16820133,\n",
       "         0.10882276, 0.15146555],\n",
       "        [0.2874676 , 0.51967025, 0.37894505, 0.364579  , 0.21628965,\n",
       "         0.15483844, 0.19923243],\n",
       "        [0.10969024, 0.5637942 , 0.25551164, 0.22823925, 0.05013973,\n",
       "         0.02069055, 0.04152629],\n",
       "        [0.0918485 , 0.57695425, 0.24361105, 0.21649179, 0.03984325,\n",
       "         0.01535675, 0.03281065],\n",
       "        [0.13890098, 0.56541103, 0.28476304, 0.25798547, 0.0710942 ,\n",
       "         0.03366474, 0.06177201],\n",
       "        [0.13480227, 0.5513434 , 0.282685  , 0.2550927 , 0.06809145,\n",
       "         0.03138962, 0.05685572],\n",
       "        [0.28962368, 0.5274071 , 0.3841526 , 0.36562333, 0.22067326,\n",
       "         0.15918408, 0.20689473],\n",
       "        [0.2733759 , 0.5267198 , 0.3739846 , 0.35574627, 0.20303172,\n",
       "         0.14085463, 0.18675421]], dtype=float32),\n",
       " array([[3.79755311e-02, 6.27603531e-01, 1.65549457e-01, 2.28784978e-01,\n",
       "         5.19819744e-02, 4.98010293e-02, 2.22970098e-02],\n",
       "        [2.80029118e-01, 5.27144313e-01, 3.75709623e-01, 4.05489266e-01,\n",
       "         2.97703028e-01, 2.89909869e-01, 2.45362490e-01],\n",
       "        [1.95891380e-01, 5.43571770e-01, 3.22057962e-01, 3.60016584e-01,\n",
       "         2.16290563e-01, 2.10248977e-01, 1.58645689e-01],\n",
       "        [5.64144831e-03, 6.98155761e-01, 7.21534416e-02, 1.20405160e-01,\n",
       "         9.47568659e-03, 8.53136554e-03, 2.22833990e-03],\n",
       "        [3.46693862e-03, 6.90317214e-01, 5.28239533e-02, 9.54355001e-02,\n",
       "         6.02024188e-03, 5.62429940e-03, 1.30442088e-03],\n",
       "        [6.59868419e-02, 6.06451511e-01, 2.11224273e-01, 2.63976365e-01,\n",
       "         8.39297175e-02, 7.93693736e-02, 4.12376523e-02],\n",
       "        [2.22912565e-01, 5.43190002e-01, 3.41133595e-01, 3.72344255e-01,\n",
       "         2.40255713e-01, 2.33955905e-01, 1.83332309e-01],\n",
       "        [3.49245578e-01, 5.18816471e-01, 4.15560573e-01, 4.36691046e-01,\n",
       "         3.61991286e-01, 3.53385538e-01, 3.20989072e-01],\n",
       "        [2.15614811e-01, 5.42376101e-01, 3.36840540e-01, 3.71003956e-01,\n",
       "         2.36162469e-01, 2.27913305e-01, 1.77028105e-01],\n",
       "        [4.15663570e-01, 5.06462872e-01, 4.49299574e-01, 4.61056709e-01,\n",
       "         4.21665996e-01, 4.13462281e-01, 3.95910442e-01],\n",
       "        [2.70346999e-01, 5.26789188e-01, 3.69515449e-01, 3.99510562e-01,\n",
       "         2.89000839e-01, 2.81750441e-01, 2.36400276e-01],\n",
       "        [5.75348316e-03, 7.01084614e-01, 7.16531947e-02, 1.20586768e-01,\n",
       "         9.67606809e-03, 8.70725140e-03, 2.35466287e-03],\n",
       "        [3.79102200e-01, 5.11911035e-01, 4.29504514e-01, 4.46174741e-01,\n",
       "         3.87937874e-01, 3.80138755e-01, 3.55041087e-01],\n",
       "        [1.17982998e-01, 5.64152002e-01, 2.59447604e-01, 3.10705274e-01,\n",
       "         1.41382501e-01, 1.35870993e-01, 8.59521180e-02],\n",
       "        [2.72034891e-02, 6.31416678e-01, 1.42479271e-01, 1.96648404e-01,\n",
       "         3.81325819e-02, 3.59461047e-02, 1.48439314e-02],\n",
       "        [1.25901446e-01, 5.69580257e-01, 2.71039248e-01, 3.18842769e-01,\n",
       "         1.48118913e-01, 1.41869992e-01, 9.21560600e-02],\n",
       "        [3.29231471e-02, 6.11003458e-01, 1.48843318e-01, 2.09916845e-01,\n",
       "         4.54533249e-02, 4.41034399e-02, 1.90524496e-02],\n",
       "        [2.22731501e-01, 5.40976286e-01, 3.43460172e-01, 3.80329430e-01,\n",
       "         2.45082811e-01, 2.37638056e-01, 1.84664890e-01],\n",
       "        [1.67673945e-01, 5.58513701e-01, 3.04122537e-01, 3.42225045e-01,\n",
       "         1.90532237e-01, 1.80847570e-01, 1.28807202e-01],\n",
       "        [3.14670950e-01, 5.24384439e-01, 3.96670341e-01, 4.20709848e-01,\n",
       "         3.31452191e-01, 3.23313385e-01, 2.83284575e-01],\n",
       "        [3.77722412e-01, 5.12357414e-01, 4.29063112e-01, 4.47144359e-01,\n",
       "         3.86271745e-01, 3.78361195e-01, 3.52764964e-01],\n",
       "        [1.73304398e-02, 6.52854085e-01, 1.16703689e-01, 1.73477128e-01,\n",
       "         2.57519968e-02, 2.38908362e-02, 8.68208986e-03],\n",
       "        [2.98359878e-02, 6.28368318e-01, 1.47855207e-01, 2.06658468e-01,\n",
       "         4.21561040e-02, 3.97334024e-02, 1.65141467e-02],\n",
       "        [3.79133850e-01, 5.08753479e-01, 4.28405374e-01, 4.45442468e-01,\n",
       "         3.87875736e-01, 3.79036099e-01, 3.53356719e-01],\n",
       "        [2.22892404e-01, 5.44791043e-01, 3.43702435e-01, 3.74988884e-01,\n",
       "         2.43431985e-01, 2.33667627e-01, 1.82267517e-01],\n",
       "        [6.18676539e-04, 7.62579501e-01, 2.50368454e-02, 5.45437969e-02,\n",
       "         1.34539208e-03, 1.15358864e-03, 1.68896717e-04],\n",
       "        [9.87414196e-02, 5.78848541e-01, 2.43224144e-01, 2.95765400e-01,\n",
       "         1.18667156e-01, 1.13675743e-01, 6.95790723e-02],\n",
       "        [6.26482889e-02, 6.06184900e-01, 2.05074653e-01, 2.64082491e-01,\n",
       "         7.99409300e-02, 7.58054405e-02, 3.94770615e-02],\n",
       "        [3.43121309e-03, 6.99692547e-01, 5.49875572e-02, 1.03824250e-01,\n",
       "         6.36834232e-03, 5.84565243e-03, 1.33561459e-03],\n",
       "        [1.26885876e-01, 5.64274490e-01, 2.66378641e-01, 3.18365663e-01,\n",
       "         1.49274617e-01, 1.42298341e-01, 9.50671062e-02],\n",
       "        [4.92064096e-02, 6.12293184e-01, 1.82831496e-01, 2.34115303e-01,\n",
       "         6.41763210e-02, 5.90488687e-02, 2.89649684e-02],\n",
       "        [2.69872934e-01, 5.31525612e-01, 3.70094568e-01, 3.98561299e-01,\n",
       "         2.86273479e-01, 2.78857708e-01, 2.34046638e-01],\n",
       "        [3.08976293e-01, 5.22478640e-01, 3.91780138e-01, 4.15270895e-01,\n",
       "         3.22381914e-01, 3.15545291e-01, 2.75413334e-01],\n",
       "        [2.45608669e-02, 6.23617172e-01, 1.31987080e-01, 1.87616318e-01,\n",
       "         3.50189321e-02, 3.33170779e-02, 1.31237293e-02],\n",
       "        [1.73394278e-01, 5.51133275e-01, 3.05696815e-01, 3.51502717e-01,\n",
       "         1.98369741e-01, 1.90800011e-01, 1.38429239e-01],\n",
       "        [9.83764985e-05, 8.21127951e-01, 1.05459457e-02, 2.86525171e-02,\n",
       "         2.56884436e-04, 2.16372122e-04, 1.97129266e-05],\n",
       "        [1.37806060e-02, 6.39283597e-01, 1.02061003e-01, 1.61181495e-01,\n",
       "         2.17890367e-02, 2.04899944e-02, 6.84457785e-03],\n",
       "        [2.43545130e-01, 5.34254730e-01, 3.53480101e-01, 3.83055955e-01,\n",
       "         2.61297733e-01, 2.53399760e-01, 2.05564931e-01],\n",
       "        [3.74420613e-01, 5.13349593e-01, 4.28900510e-01, 4.46014434e-01,\n",
       "         3.83708298e-01, 3.75438929e-01, 3.48256916e-01],\n",
       "        [8.96490738e-02, 5.92118859e-01, 2.39786163e-01, 2.90572912e-01,\n",
       "         1.09497763e-01, 1.03585087e-01, 5.97105771e-02],\n",
       "        [1.60498414e-02, 6.41152263e-01, 1.09923534e-01, 1.67898551e-01,\n",
       "         2.46035010e-02, 2.34668534e-02, 8.09328258e-03],\n",
       "        [3.65842879e-01, 5.12047887e-01, 4.22800034e-01, 4.39908504e-01,\n",
       "         3.75105202e-01, 3.65725517e-01, 3.38207394e-01],\n",
       "        [4.19791579e-01, 5.03730118e-01, 4.49871778e-01, 4.62694466e-01,\n",
       "         4.24260616e-01, 4.16813970e-01, 4.01963323e-01],\n",
       "        [2.00314909e-01, 5.46488941e-01, 3.23656291e-01, 3.59816194e-01,\n",
       "         2.19394401e-01, 2.13274151e-01, 1.62853718e-01],\n",
       "        [1.23714805e-01, 5.59978127e-01, 2.64665216e-01, 3.15440953e-01,\n",
       "         1.47588909e-01, 1.45259529e-01, 9.29083824e-02],\n",
       "        [9.70172063e-02, 5.71891606e-01, 2.37760127e-01, 2.87379503e-01,\n",
       "         1.16831161e-01, 1.11038640e-01, 6.73305914e-02],\n",
       "        [3.68353655e-03, 7.18615294e-01, 5.98709434e-02, 1.04962952e-01,\n",
       "         6.52904436e-03, 5.85198821e-03, 1.35500985e-03],\n",
       "        [2.44433790e-01, 5.34430563e-01, 3.54983270e-01, 3.90893757e-01,\n",
       "         2.64721572e-01, 2.56890208e-01, 2.08227664e-01],\n",
       "        [4.55827087e-01, 5.00240922e-01, 4.68658745e-01, 4.76093262e-01,\n",
       "         4.57663029e-01, 4.49999124e-01, 4.42854494e-01],\n",
       "        [4.04429078e-01, 5.09154260e-01, 4.44033027e-01, 4.56586361e-01,\n",
       "         4.10579056e-01, 4.02204305e-01, 3.81794274e-01],\n",
       "        [1.52911350e-01, 5.51989019e-01, 2.88568079e-01, 3.31102759e-01,\n",
       "         1.74190834e-01, 1.66907400e-01, 1.16294272e-01],\n",
       "        [1.88678995e-01, 5.52671909e-01, 3.20014566e-01, 3.56267035e-01,\n",
       "         2.10098207e-01, 2.01533005e-01, 1.48977250e-01],\n",
       "        [1.28703251e-01, 5.68877459e-01, 2.73192048e-01, 3.20983052e-01,\n",
       "         1.49944246e-01, 1.44482777e-01, 9.41902101e-02],\n",
       "        [4.72784400e-01, 4.98379022e-01, 4.78616267e-01, 4.83385593e-01,\n",
       "         4.72640783e-01, 4.66029644e-01, 4.62501615e-01],\n",
       "        [1.61822796e-01, 5.61454713e-01, 3.02287728e-01, 3.40264320e-01,\n",
       "         1.83484554e-01, 1.76814482e-01, 1.23264894e-01],\n",
       "        [2.03688032e-04, 8.14006150e-01, 1.53592965e-02, 3.78032885e-02,\n",
       "         4.85755765e-04, 4.24385449e-04, 4.53176326e-05],\n",
       "        [5.34049459e-02, 6.05630279e-01, 1.91527322e-01, 2.50894487e-01,\n",
       "         7.03374520e-02, 6.55366629e-02, 3.25212926e-02],\n",
       "        [2.14110553e-01, 5.40162921e-01, 3.35548460e-01, 3.69112939e-01,\n",
       "         2.35245973e-01, 2.25513652e-01, 1.74993962e-01],\n",
       "        [1.64790124e-01, 5.61550438e-01, 3.06190521e-01, 3.44746977e-01,\n",
       "         1.87347293e-01, 1.78176463e-01, 1.25622153e-01],\n",
       "        [1.16489239e-01, 5.69013238e-01, 2.60604799e-01, 3.11857641e-01,\n",
       "         1.38165697e-01, 1.32392734e-01, 8.36500227e-02],\n",
       "        [3.46667737e-01, 5.16924322e-01, 4.13328379e-01, 4.34215605e-01,\n",
       "         3.57721269e-01, 3.50240827e-01, 3.17175388e-01],\n",
       "        [4.77650464e-02, 6.19509101e-01, 1.85385197e-01, 2.44113639e-01,\n",
       "         6.35813400e-02, 6.03334829e-02, 2.89622005e-02],\n",
       "        [7.04833493e-02, 5.90155959e-01, 2.11114302e-01, 2.65318960e-01,\n",
       "         9.05788019e-02, 8.57155919e-02, 4.62143235e-02],\n",
       "        [2.23151788e-01, 5.37357390e-01, 3.40047628e-01, 3.77030492e-01,\n",
       "         2.42287964e-01, 2.35320181e-01, 1.85171828e-01],\n",
       "        [2.95674443e-01, 5.23609579e-01, 3.83409262e-01, 4.10224199e-01,\n",
       "         3.10230672e-01, 3.02569240e-01, 2.61100620e-01],\n",
       "        [1.39629379e-01, 5.67486942e-01, 2.85472214e-01, 3.27836663e-01,\n",
       "         1.60885826e-01, 1.54280394e-01, 1.03268139e-01],\n",
       "        [5.03742509e-02, 6.03897095e-01, 1.81656927e-01, 2.42328271e-01,\n",
       "         6.58459887e-02, 6.26086071e-02, 3.12507749e-02],\n",
       "        [7.22415149e-02, 5.87988198e-01, 2.11576089e-01, 2.69044966e-01,\n",
       "         9.05922279e-02, 8.56942087e-02, 4.73202690e-02],\n",
       "        [2.32146177e-02, 6.38793707e-01, 1.33254007e-01, 1.90408841e-01,\n",
       "         3.38766985e-02, 3.11000571e-02, 1.22273071e-02],\n",
       "        [1.66890398e-01, 5.57104290e-01, 3.02051604e-01, 3.47318918e-01,\n",
       "         1.88219577e-01, 1.83988124e-01, 1.31613746e-01],\n",
       "        [7.37578496e-02, 6.03303075e-01, 2.18492702e-01, 2.75723398e-01,\n",
       "         9.35060084e-02, 8.90565366e-02, 4.85715047e-02],\n",
       "        [1.45963788e-01, 5.57191193e-01, 2.84409523e-01, 3.31758112e-01,\n",
       "         1.69568002e-01, 1.63120955e-01, 1.11657351e-01],\n",
       "        [6.48534074e-02, 5.98503590e-01, 2.05786332e-01, 2.59005934e-01,\n",
       "         8.24172795e-02, 7.67215565e-02, 4.13573533e-02],\n",
       "        [2.37912405e-02, 6.49861336e-01, 1.35661781e-01, 1.90314502e-01,\n",
       "         3.39253098e-02, 3.16868536e-02, 1.22215329e-02],\n",
       "        [2.09889114e-01, 5.46313226e-01, 3.34928244e-01, 3.69354606e-01,\n",
       "         2.29429230e-01, 2.20229119e-01, 1.70055836e-01],\n",
       "        [5.18944077e-02, 6.00509644e-01, 1.84949577e-01, 2.42321998e-01,\n",
       "         6.70624301e-02, 6.29771948e-02, 3.13936286e-02],\n",
       "        [4.08233069e-02, 6.08084261e-01, 1.65687218e-01, 2.20971957e-01,\n",
       "         5.52871414e-02, 5.32829575e-02, 2.40613278e-02],\n",
       "        [3.84930402e-01, 5.08890986e-01, 4.31534320e-01, 4.48694915e-01,\n",
       "         3.94159287e-01, 3.85635763e-01, 3.61235380e-01],\n",
       "        [1.18326306e-01, 5.70064247e-01, 2.63009995e-01, 3.11645240e-01,\n",
       "         1.40556470e-01, 1.33792669e-01, 8.49019513e-02],\n",
       "        [2.42712781e-01, 5.35254240e-01, 3.54324609e-01, 3.85069072e-01,\n",
       "         2.60449052e-01, 2.50962466e-01, 2.03142524e-01],\n",
       "        [1.99293792e-01, 5.48013151e-01, 3.26204598e-01, 3.68476629e-01,\n",
       "         2.20633581e-01, 2.13111684e-01, 1.61898062e-01],\n",
       "        [3.58129144e-01, 5.14422894e-01, 4.18224156e-01, 4.37321663e-01,\n",
       "         3.69008303e-01, 3.61328006e-01, 3.31272036e-01],\n",
       "        [2.69063622e-01, 5.30474007e-01, 3.69833440e-01, 3.98456514e-01,\n",
       "         2.85688192e-01, 2.76131123e-01, 2.31791586e-01],\n",
       "        [4.59439903e-01, 4.99392539e-01, 4.71222401e-01, 4.78143990e-01,\n",
       "         4.60554928e-01, 4.53333586e-01, 4.47116047e-01],\n",
       "        [2.51635522e-01, 5.32408655e-01, 3.57344925e-01, 3.82151037e-01,\n",
       "         2.67088324e-01, 2.60147065e-01, 2.12959334e-01]], dtype=float32),\n",
       " array([[0.3592105 , 0.50855625, 0.378976  , 0.38359421, 0.3953355 ,\n",
       "         0.34796777, 0.3126808 ],\n",
       "        [0.23450416, 0.5376583 , 0.26204008, 0.27956107, 0.28195336,\n",
       "         0.2147259 , 0.15483147],\n",
       "        [0.19172537, 0.5404746 , 0.21516079, 0.2443048 , 0.2414059 ,\n",
       "         0.17067732, 0.11166929],\n",
       "        [0.13745938, 0.5700698 , 0.15933125, 0.18384494, 0.18157315,\n",
       "         0.11569735, 0.06171182],\n",
       "        [0.06614018, 0.59933823, 0.09292593, 0.11116638, 0.10633119,\n",
       "         0.05422169, 0.02188586],\n",
       "        [0.2662022 , 0.52882725, 0.3015991 , 0.31052893, 0.31707487,\n",
       "         0.25327036, 0.2004103 ],\n",
       "        [0.22475424, 0.53524566, 0.24607548, 0.27229863, 0.27056244,\n",
       "         0.20352471, 0.14363562],\n",
       "        [0.2383707 , 0.53737503, 0.2574415 , 0.27847818, 0.28026778,\n",
       "         0.21455929, 0.15303698],\n",
       "        [0.2728596 , 0.5308977 , 0.30548865, 0.30979645, 0.31407276,\n",
       "         0.2578667 , 0.20257264],\n",
       "        [0.09872909, 0.5938085 , 0.12845567, 0.14393768, 0.14251974,\n",
       "         0.082197  , 0.03831222],\n",
       "        [0.15765876, 0.5616123 , 0.18817152, 0.20917042, 0.20358382,\n",
       "         0.13956937, 0.082344  ],\n",
       "        [0.42849827, 0.49207044, 0.4297705 , 0.43942297, 0.45410234,\n",
       "         0.41682428, 0.40429726],\n",
       "        [0.29871047, 0.5244476 , 0.3274116 , 0.33305162, 0.33998165,\n",
       "         0.28442192, 0.23369366],\n",
       "        [0.1129784 , 0.59338444, 0.14029641, 0.15557663, 0.15311268,\n",
       "         0.09450886, 0.04505274],\n",
       "        [0.10400998, 0.5793427 , 0.13010137, 0.15253463, 0.1508589 ,\n",
       "         0.0870499 , 0.04223052],\n",
       "        [0.27713937, 0.5327377 , 0.30109498, 0.31429487, 0.31806377,\n",
       "         0.2551393 , 0.20029454],\n",
       "        [0.13926555, 0.57822376, 0.16557458, 0.1821793 , 0.1807701 ,\n",
       "         0.11823077, 0.06278462],\n",
       "        [0.13550355, 0.56759006, 0.16812013, 0.18862136, 0.18402211,\n",
       "         0.11757667, 0.06650871],\n",
       "        [0.11832035, 0.57374495, 0.16437575, 0.17534624, 0.17196241,\n",
       "         0.10799275, 0.05967843],\n",
       "        [0.36658233, 0.50294787, 0.37841004, 0.3913256 , 0.4035739 ,\n",
       "         0.35250655, 0.32051757],\n",
       "        [0.03318644, 0.6450103 , 0.05337756, 0.06555711, 0.05948665,\n",
       "         0.0257029 , 0.00753636],\n",
       "        [0.32118413, 0.51341444, 0.34245953, 0.35506445, 0.36385977,\n",
       "         0.3071163 , 0.26212463],\n",
       "        [0.10548911, 0.5799683 , 0.14397968, 0.15787639, 0.1545779 ,\n",
       "         0.09306461, 0.0467044 ],\n",
       "        [0.14578569, 0.5613507 , 0.17501962, 0.19515815, 0.1979184 ,\n",
       "         0.12789406, 0.07336298],\n",
       "        [0.11850542, 0.55712897, 0.15129253, 0.18027268, 0.17136379,\n",
       "         0.10563893, 0.05752295],\n",
       "        [0.31062034, 0.5151496 , 0.32739812, 0.34168926, 0.3536688 ,\n",
       "         0.29214668, 0.24490072],\n",
       "        [0.1651449 , 0.5656986 , 0.19610716, 0.21624333, 0.20654508,\n",
       "         0.1430941 , 0.08697592],\n",
       "        [0.3263386 , 0.5133866 , 0.3388564 , 0.3575638 , 0.36431134,\n",
       "         0.3053745 , 0.2621261 ],\n",
       "        [0.10405941, 0.59557223, 0.14318429, 0.1527795 , 0.14572579,\n",
       "         0.08937906, 0.04404093],\n",
       "        [0.0723164 , 0.61447483, 0.10263377, 0.11266942, 0.10777669,\n",
       "         0.05922917, 0.02414755],\n",
       "        [0.29433674, 0.52683383, 0.3228653 , 0.3313612 , 0.33513263,\n",
       "         0.27818882, 0.22737989],\n",
       "        [0.26076782, 0.51916677, 0.2807874 , 0.30932298, 0.30957878,\n",
       "         0.24184707, 0.18787587],\n",
       "        [0.23853233, 0.53163964, 0.27273756, 0.28833762, 0.28659728,\n",
       "         0.2245843 , 0.16727929],\n",
       "        [0.28306046, 0.5290927 , 0.3122729 , 0.31907105, 0.32504287,\n",
       "         0.26615927, 0.2124288 ],\n",
       "        [0.17688605, 0.56172156, 0.20187564, 0.22030759, 0.21956626,\n",
       "         0.15315224, 0.09346836],\n",
       "        [0.13926555, 0.57822376, 0.16557458, 0.1821793 , 0.1807701 ,\n",
       "         0.11823077, 0.06278462],\n",
       "        [0.26063156, 0.53070205, 0.28556186, 0.3025614 , 0.30445752,\n",
       "         0.2400218 , 0.18473598],\n",
       "        [0.07626472, 0.60509205, 0.12058145, 0.12079197, 0.12150345,\n",
       "         0.06934292, 0.03007755],\n",
       "        [0.18584968, 0.5650234 , 0.21531618, 0.22745195, 0.22489108,\n",
       "         0.16344427, 0.10114455],\n",
       "        [0.11691218, 0.58549213, 0.14939061, 0.16403054, 0.16034734,\n",
       "         0.10085577, 0.05014113],\n",
       "        [0.05228225, 0.6263595 , 0.08802764, 0.09222618, 0.09019294,\n",
       "         0.04516493, 0.01689239],\n",
       "        [0.28728014, 0.51921344, 0.30631918, 0.3291484 , 0.33287042,\n",
       "         0.26729575, 0.2165134 ],\n",
       "        [0.19332781, 0.5394974 , 0.21934809, 0.24549651, 0.24513735,\n",
       "         0.17269431, 0.11587126],\n",
       "        [0.22406174, 0.5299803 , 0.2592923 , 0.2783979 , 0.28165776,\n",
       "         0.21032953, 0.15584975],\n",
       "        [0.3309726 , 0.519771  , 0.34315136, 0.3568595 , 0.36350805,\n",
       "         0.3099261 , 0.26270616],\n",
       "        [0.24780174, 0.530995  , 0.27490792, 0.29254246, 0.296213  ,\n",
       "         0.22755516, 0.17197855],\n",
       "        [0.23834252, 0.5365778 , 0.27121365, 0.28463793, 0.28894123,\n",
       "         0.22149965, 0.16418934],\n",
       "        [0.14339481, 0.5551866 , 0.17568177, 0.19803827, 0.20024501,\n",
       "         0.12622336, 0.07386404],\n",
       "        [0.13026308, 0.5757745 , 0.16375998, 0.1819053 , 0.17380653,\n",
       "         0.11369714, 0.0605723 ],\n",
       "        [0.08768804, 0.6030321 , 0.1143557 , 0.12839036, 0.12554441,\n",
       "         0.07115109, 0.03078101],\n",
       "        [0.24680346, 0.5338556 , 0.27431762, 0.29042417, 0.29491755,\n",
       "         0.22850718, 0.16974518],\n",
       "        [0.35752994, 0.5062985 , 0.36582604, 0.3827435 , 0.38985223,\n",
       "         0.33921453, 0.30234355],\n",
       "        [0.19977912, 0.5385695 , 0.22826687, 0.2542626 , 0.25379294,\n",
       "         0.17959481, 0.12370514],\n",
       "        [0.15523396, 0.5605734 , 0.18750001, 0.20506743, 0.20562524,\n",
       "         0.13693032, 0.08092378],\n",
       "        [0.18416879, 0.5396601 , 0.21115533, 0.23753427, 0.24312012,\n",
       "         0.16433111, 0.10944761],\n",
       "        [0.1841109 , 0.5558843 , 0.2298856 , 0.23443228, 0.23677044,\n",
       "         0.17206132, 0.11285093],\n",
       "        [0.18981728, 0.54457355, 0.23895732, 0.2443132 , 0.24513142,\n",
       "         0.18008189, 0.12369866],\n",
       "        [0.09135261, 0.59574986, 0.11750496, 0.13320439, 0.13296722,\n",
       "         0.07485432, 0.03320788],\n",
       "        [0.09120014, 0.5796266 , 0.11494597, 0.13954017, 0.13686894,\n",
       "         0.07620938, 0.03539973],\n",
       "        [0.10189184, 0.58001614, 0.13613825, 0.15419893, 0.148009  ,\n",
       "         0.08978654, 0.04398408],\n",
       "        [0.1491426 , 0.57395166, 0.1801031 , 0.19663183, 0.19355308,\n",
       "         0.12982543, 0.07235119],\n",
       "        [0.20536694, 0.5534439 , 0.23947188, 0.25150698, 0.25009203,\n",
       "         0.18504679, 0.12500007],\n",
       "        [0.1965622 , 0.54258   , 0.21738534, 0.24541648, 0.24743691,\n",
       "         0.17242378, 0.11394145],\n",
       "        [0.05010756, 0.63174564, 0.07865001, 0.08739869, 0.08252318,\n",
       "         0.04062418, 0.01428078],\n",
       "        [0.21283498, 0.5426773 , 0.23520947, 0.25540817, 0.2594832 ,\n",
       "         0.18880534, 0.12872267],\n",
       "        [0.24338184, 0.5263293 , 0.2634218 , 0.29107165, 0.29717198,\n",
       "         0.22119467, 0.16541778],\n",
       "        [0.17900988, 0.5609812 , 0.21978556, 0.22634391, 0.22907951,\n",
       "         0.16407847, 0.10440788],\n",
       "        [0.22203141, 0.5459319 , 0.25572777, 0.26594764, 0.26951   ,\n",
       "         0.20393167, 0.14348097],\n",
       "        [0.19840136, 0.5393611 , 0.23431776, 0.25441888, 0.25205195,\n",
       "         0.18360761, 0.12736647],\n",
       "        [0.17667358, 0.5564441 , 0.2032625 , 0.22247182, 0.22258309,\n",
       "         0.15390421, 0.09582236],\n",
       "        [0.3472677 , 0.5038268 , 0.35911605, 0.37721512, 0.38764176,\n",
       "         0.33175308, 0.29492122],\n",
       "        [0.14319721, 0.5712519 , 0.17012228, 0.1880805 , 0.18703254,\n",
       "         0.12309143, 0.06738587],\n",
       "        [0.07220703, 0.6063585 , 0.11972987, 0.11897459, 0.11942687,\n",
       "         0.0668315 , 0.02938423],\n",
       "        [0.18725409, 0.5504189 , 0.21299995, 0.23455851, 0.23113148,\n",
       "         0.1661112 , 0.10590528],\n",
       "        [0.13448606, 0.5652213 , 0.16194522, 0.18429779, 0.18747157,\n",
       "         0.11624102, 0.06358155],\n",
       "        [0.1006892 , 0.6057803 , 0.14268275, 0.14581998, 0.142086  ,\n",
       "         0.08804718, 0.04157973],\n",
       "        [0.16416404, 0.5769947 , 0.20011646, 0.20934214, 0.20585226,\n",
       "         0.1436671 , 0.08474444],\n",
       "        [0.05955175, 0.61186266, 0.09225836, 0.10408411, 0.09867699,\n",
       "         0.05050219, 0.02026148],\n",
       "        [0.07095058, 0.6029379 , 0.10685542, 0.11746358, 0.11508662,\n",
       "         0.06173397, 0.02635504],\n",
       "        [0.3828088 , 0.49882153, 0.38725397, 0.40287447, 0.41534564,\n",
       "         0.3658292 , 0.33754754],\n",
       "        [0.09361636, 0.5965348 , 0.13955292, 0.14325342, 0.13936818,\n",
       "         0.08472191, 0.04070278],\n",
       "        [0.04592662, 0.6463937 , 0.06991214, 0.07941667, 0.07427236,\n",
       "         0.0366763 , 0.01158273],\n",
       "        [0.13481943, 0.5734489 , 0.18489577, 0.1909891 , 0.18918748,\n",
       "         0.1255421 , 0.07210236],\n",
       "        [0.29472896, 0.5123478 , 0.31100056, 0.33624497, 0.34197754,\n",
       "         0.27561426, 0.2271473 ],\n",
       "        [0.04323513, 0.6450989 , 0.06428174, 0.07475924, 0.06959577,\n",
       "         0.03276104, 0.01019674]], dtype=float32)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e493d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_sk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a7c099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for yp in y_preds:\n",
    "    y_preds_sk.append(np.where(yp > 0.5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25ae7b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_sk[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dbea810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "44402f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2257703081232493"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "hl = []\n",
    "for train_index, test_index in kf.split(X):     \n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    l = hamming_loss(y_test, y_preds_sk[k])\n",
    "    hl.append(l)\n",
    "    k+=1\n",
    "HL = np.mean(hl)\n",
    "HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d4bebb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_dict = dict()\n",
    "for i,label in enumerate(labels):\n",
    "    f1_dict[label] = []\n",
    "    k = 0\n",
    "    for train_index, test_index in kf.split(X):     \n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_pred_label = y_preds_sk[k].T[i]\n",
    "        f1 = f1_score(y_test.T[i], y_pred_label, average=\"binary\")\n",
    "        f1_dict[label].append(f1)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d46f7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "for label in labels:\n",
    "    f1_list.append(np.mean(f1_dict[label]))\n",
    "macro_f1_val = np.mean(f1_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6f0d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), f1_list)\n",
    "plt.title(f\"F1 score per label  (macro-f1: {macro_f1_val:.3f}, Hamming Loss: {HL:.3f}, k=3)\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8a37fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8a6d970a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(f1_dict.keys(), rate)\n",
    "plt.title(f\"そのラベルを持つ顔写真は全体の何割か\")\n",
    "plt.show() ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427a231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
